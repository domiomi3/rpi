{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matusd/.conda/envs/rpi/lib/python3.8/site-packages/Bio/__init__.py:138: BiopythonWarning: You may be importing Biopython from inside the source tree. This is bad practice and might lead to downstream issues. In particular, you might encounter ImportErrors due to missing compiled C extensions. We recommend that you try running your code from outside the source tree. If you are outside the source tree then you have a setup.py file in an unexpected directory: /home/matusd/.conda/envs/rpi/lib/python3.8/site-packages\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import choice\n",
    "from pathlib import Path\n",
    "\n",
    "# src_dir = Path.cwd().parent\n",
    "# sys.path.append(str(src_dir))\n",
    "from utils import load_rna_inter_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset Creation\n",
    "This dataset helps to create our final dataset with the given splits (Training Set, Test Set, Random Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = \"/work/dlclarge1/matusd-rpi/RPI/\" # change this to your working directory\n",
    "ANNOT_DIR = \"data/annotations/\"\n",
    "INTER_DIR = \"data/interactions/\"\n",
    "EMB_DIR = \"data/embeddings/\"\n",
    "RNAINTER_DIR = \"data/RNAInter/\"\n",
    "\n",
    "os.chdir(WORKING_DIR)\n",
    "\n",
    "if not os.path.exists(INTER_DIR):\n",
    "    os.makedirs(INTER_DIR)\n",
    "    \n",
    "if not os.path.exists(EMB_DIR):\n",
    "    os.makedirs(EMB_DIR)\n",
    "    \n",
    "# limit on number of interactions per protein/RNA\n",
    "PROTEIN_INTER = 150\n",
    "RNA_INTER = 150\n",
    "\n",
    "TEST_SET_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RNAInter DB with interaction data\n",
    "\n",
    "# Create directory\n",
    "if not os.path.exists(RNAINTER_DIR):\n",
    "    os.makedirs(RNAINTER_DIR)\n",
    "\n",
    "rnainter_path = RNAINTER_DIR + \"Download_data_RP.txt\"\n",
    "\n",
    "# Download data\n",
    "if not os.path.exists(rnainter_path):\n",
    "    os.chdir(RNAINTER_DIR)\n",
    "\n",
    "    !wget http://www.rnainter.org/raidMedia/download/Download_data_RP.tar.gz\n",
    "    !tar -xf Download_data_RP.tar.gz\n",
    "    !rm Download_data_RP.tar.gz\n",
    "\n",
    "    os.chdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of RNA sequences: 7,847\n",
      "Number of protein sequences: 26,575\n"
     ]
    }
   ],
   "source": [
    "# Prepare RNA sequences DataFrame\n",
    "rna_sequences = pd.read_parquet(os.path.join(ANNOT_DIR, 'rna_short_families.parquet'), engine='pyarrow')\n",
    "\n",
    "# Drop entries lacking crucial information or duplicated\n",
    "rna_sequences = rna_sequences.dropna(subset=['Sequence_1', 'Raw_ID1', 'Sequence_1_family'])\n",
    "rna_sequences = rna_sequences.drop_duplicates(subset=['Raw_ID1'])\n",
    "\n",
    "print(f\"Number of RNA sequences: {rna_sequences.shape[0]:,}\")\n",
    "\n",
    "# Prepare protein sequences DataFrame\n",
    "protein_sequences = pd.read_parquet(os.path.join(ANNOT_DIR, 'proteins_short_clans.parquet'), engine='pyarrow')\n",
    "\n",
    "# Drop entries lacking crucial information or duplicated\n",
    "protein_sequences = protein_sequences.dropna(subset=['Sequence_2', 'Raw_ID2', 'Sequence_2_clan'])\n",
    "protein_sequences= protein_sequences.drop_duplicates(subset=['Raw_ID2'])\n",
    "\n",
    "print(f\"Number of protein sequences: {protein_sequences.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions in RNAInter: 37,067,587\n"
     ]
    }
   ],
   "source": [
    "# Load raw RNAInter database\n",
    "rna_inter_df = load_rna_inter_csv(rnainter_path)\n",
    "print(f\"Number of interactions in RNAInter: {rna_inter_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (positive) interactions with annotated entries: 488,184 \n",
      "\n",
      "RPI dataframe columns: \n",
      " ['RNAInterID', 'Interactor1.Symbol', 'Category1', 'Species1', 'Interactor2.Symbol', 'Category2', 'Species2', 'Raw_ID1', 'Raw_ID2', 'score', 'strong', 'weak', 'predict', 'Sequence_1_rfam_q_accession', 'Sequence_1_family', 'Sequence_1_rfam_t_accession', 'Sequence_1_rfam_description', 'Sequence_1_rfam_e_value', 'Sequence_1', 'Sequence_1_len', 'Sequence_1_ID', 'Sequence_2_clan', 'Sequence_2_ID', 'Sequence_2', 'Sequence_2_len', 'interaction'] \n",
      "\n",
      "RPI sample entries: \n",
      "    RNAInterID Interactor1.Symbol Category1      Species1 Interactor2.Symbol Category2      Species2         Raw_ID1     Raw_ID2   score strong       weak                                    predict Sequence_1_rfam_q_accession Sequence_1_family Sequence_1_rfam_t_accession              Sequence_1_rfam_description  Sequence_1_rfam_e_value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Sequence_1  Sequence_1_len Sequence_1_ID Sequence_2_clan Sequence_2_ID                                                                                                                                                                                                                                     Sequence_2  Sequence_2_len  interaction\n",
      "0  RP34117562      2010103J01Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus      NCBI:69889  NCBI:56758  0.1229    NaN        NaN  Scan pipeline widely used MATCH algorithm                           -           mir-192                     RF00130           mir-192/215 microRNA precursor             1.100000e-16                                                                                                                                                                                                                                                    ACUCAGGACUUCCAGGUAAGGAGCCGCUGCUGUCCUCUUGGUCCUCUGUUCUCUCUUUAUAAGCAAAAGGCACAGGACAGGAUCUCUGCUGGAAGUGACCGUGGAAAGAACGAGUUCAAGUGCUAGGUCAGCAGAGGACCCAGCCAUGGAGACUACGGAGCACGGAGCUCUCAGCAUCAACGGUGUACAGGAGAAUGACCUAUGAUUUGACAGACCGUGCAGCUGUGUAUGUCUGUCAUUCUGUAGGCCAAUAUUCUGUAUGUCACUGCUACUUAAAAUCCGGACAUCGGCAAACACCCUCUGAGCGCUGUGCAGCAGAUCACGGGAGAGUCUGUAGCAUGGCAGGAGAAUGUGCUGACAAAAUAAAAUGAGUGCUUCUGUGUA             384    1907071096          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n",
      "1  RP34118868      2310002D06Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus      NCBI:69522  NCBI:56758  0.1229    NaN        NaN  Scan pipeline widely used MATCH algorithm                           -                U3                     RF00012                   Small nucleolar RNA U3             9.900000e-07                                                                                                                        AGAUUCUGCUUGCUGUAGCCAAUAAGCACAACAGCUUGGAAGCAAUGCUGCAGGCAGCCGGCACCCUCACUGUGCAGCUGAGAAAACUGAGGCUGAGAAUUGACCGGAGCCACCUCAUAGAUGGCUUCAUUCGCAAGCCUGACCUGUCUUGGAUUUUCCGAAGAGUCAACCUACCUGACAUCAUCCAAAAAGCACCACCCUGUCCACUCUGCUCCUGGCAUUUAAGAUCCUCCAGUAUCUAGACUUGCCCAGUCUGGCCAGUCUCAACUCACACCAGGUCUUUGCCAGUAUCCAGCAUGCUCUCAUGAGAUAUUAUCCUGAGGGCCUUGGCUGUCCCUGCCCUUUCCUUAUUCUUCUCUUCCUUUUUGGGAUUACCCUCCUAUUCUCCAGAUUUAUCCACUUUCUCUGGGAAGCCUUCCUAAAGACCACUUUGCAAGACUAUACUUUCAGGAAUCAUUUCUGUAGUUCGUUACUGAAGACCAGUUUGCAAUAAAUUAUUUCUUCCUCC             508     356460946          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n",
      "2  RP09023616      5430416N02Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus  NCBI:100503199  NCBI:56758  0.1229    NaN  HITS-CLIP  Scan pipeline widely used MATCH algorithm                           -         adapt33_3                     RF02257  Adaptive response 33 conserved region 3             9.600000e-27  CCGUGGGCACGUUCUCGCUUCCAUUCGGUCCUCCUUUUGUUAACGCUCUGGCAUCAUGUCUACGCCAGCUCCCGCGCAAUCCGGCGCCAUCGCGCUUUGGGCGAGCAUGGCCAUGGGGAGUAGAGAGGUGGAAACCGAGCUGACGCCUGCCUGACCCUGGCGAUGGUGGCGCGCGCCGGGAAGGACUGAUUGGAGAAUGGCGCCAAAUGGGUCACGGAUGGCGAGGGGGCACAGGAGCUCUCGAUGUGACCUGGCGCUGUGGAUGUGAUGCACAGCAGCUUGAGUGGGACUGCUCCGCUGUCCUCAUGAGAGAACGCUUUUUCUGAAGAUGGGAGGUGGCUAAUGAAAGAAGGAAUUGUGUUCUCGGUGAUGCCUGGAAGAGAUGCGUGACGUUGGAAGAUGAUUACGAAAUACAGGAAAGGAAUGAAAUCAAAGGAUGUUUUUUGUAAGAGUAACACUUACAGAAAUAUUCAUUAAUUUGAAGAUUUAUAUAAGGCCUGGUGACCUCCGUUAAUUCCUGGGACCCACAGUGUGGAAGAAGAGACCUGACUCCUGAAAGUUGUCUUCUGACCACAUAUACACAAUAUGUAAAUAAAUGUAAUUAAAAAAUCAAAAUAGUAAAACUG             626     300360574          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n"
     ]
    }
   ],
   "source": [
    "# Merge RNAInter and sequences DataFrames\n",
    "rpi_df = rna_inter_df.merge(rna_sequences, on='Raw_ID1', how='inner').merge(protein_sequences, on='Raw_ID2', how='inner')\n",
    "\n",
    "# Create interaction label for classification\n",
    "rpi_df['interaction'] = True\n",
    "\n",
    "print(f\"Number of (positive) interactions with annotated entries: {rpi_df.shape[0]:,} \\n\")\n",
    "print(f\"RPI dataframe columns: \\n {rpi_df.columns.to_list()} \\n\")\n",
    "print(f\"RPI sample entries: \\n {rpi_df.head(3).to_string()}\")\n",
    "\n",
    "# Save RPI DataFrame\n",
    "rpi_df.to_parquet(os.path.join(INTER_DIR, 'raw_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid RNA interactors removed: \n",
      " Category1\n",
      "mRNA                       25010\n",
      "retained_intron              128\n",
      "nonsense_mediated_decay       41\n",
      "unknown                       17\n",
      "misc_RNA                       8\n",
      "Mt_tRNA                        4\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Number of interactions with valid RNA interactors: 462,976 \n",
      "\n",
      "Invalid protein interactors removed: \n",
      " Series([], Name: count, dtype: int64) \n",
      "\n",
      "Number of interactions with valid protein interactors: 462,976 \n",
      "\n",
      "Number of interactions after removing duplicates: 462,935\n",
      "Number of interactions after limiting number of interactions per protein/RNA: 40,739 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpi_df = pd.read_parquet(os.path.join(INTER_DIR, 'raw_interactions.parquet'), engine='pyarrow')\n",
    "\n",
    "# Remove invalid RNA interactors\n",
    "# (we remove all mRNAs as the RNA-FM model has been trained only on ncRNAs)\n",
    "valid_rna = ['lncRNA', 'snRNA', 'snoRNA', 'scaRNA', 'miRNA', 'circRNA', 'rRNA',\n",
    "       'ribozyme', 'sncRNA', 'ncRNA', 'sRNA', 'vtRNAs', 'pseudo', 'others']\n",
    "print(f\"Invalid RNA interactors removed: \\n {rpi_df[~rpi_df['Category1'].isin(valid_rna)]['Category1'].value_counts()} \\n\")\n",
    "rpi_df = rpi_df[rpi_df['Category1'].isin(valid_rna)]\n",
    "print(f\"Number of interactions with valid RNA interactors: {rpi_df.shape[0]:,} \\n\")\n",
    "\n",
    "# Remove invalid protein interactors\n",
    "valid_protein = ['TF', 'RBP', 'protein']\n",
    "print(f\"Invalid protein interactors removed: \\n {rpi_df[~rpi_df['Category2'].isin(valid_protein)]['Category2'].value_counts()} \\n\")\n",
    "rpi_df = rpi_df[rpi_df['Category2'].isin(valid_protein)]\n",
    "print(f\"Number of interactions with valid protein interactors: {rpi_df.shape[0]:,} \\n\")\n",
    "\n",
    "# Remove interactions with more than one occurence and with duplicated both interactors\n",
    "rpi_df = rpi_df.drop_duplicates(subset=['RNAInterID'])\n",
    "rpi_df = rpi_df.drop_duplicates(subset=['Raw_ID1', 'Raw_ID2'])\n",
    "print(f\"Number of interactions after removing duplicates: {rpi_df.shape[0]:,}\")\n",
    "\n",
    "# Limit number of interactions per protein/RNA\n",
    "limit_rpi_df = rpi_df.groupby(by=['Raw_ID1']).filter(lambda x: len(x) < RNA_INTER)\n",
    "limit_rpi_df = limit_rpi_df.groupby(by=['Raw_ID2']).filter(lambda x: len(x) < PROTEIN_INTER)\n",
    "print(f\"Number of interactions after limiting number of interactions per protein/RNA: {limit_rpi_df.shape[0]:,} \\n\")\n",
    "limit_rpi_df.to_parquet(os.path.join(INTER_DIR, 'limited_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique RNA sequences: 4,168\n",
      "Number of RNA families: 1,148 \n",
      "\n",
      "Number of unique protein sequences: 1,306\n",
      "Number of protein clans: 152\n"
     ]
    }
   ],
   "source": [
    "# Quick data analysis\n",
    "print(f\"Number of unique RNA sequences: {limit_rpi_df['Sequence_1'].nunique():,}\")\n",
    "print(f\"Number of RNA families: {limit_rpi_df['Sequence_1_family'].nunique():,} \\n\")\n",
    "\n",
    "# for embeddings, we use \"Sequence_1_ID\" as an identifier of RNA sequences\n",
    "assert limit_rpi_df['Raw_ID1'].nunique() == limit_rpi_df['Sequence_1_ID'].nunique()\n",
    "\n",
    "print(f\"Number of unique protein sequences: {limit_rpi_df['Sequence_2'].nunique():,}\")\n",
    "print(f\"Number of protein clans: {limit_rpi_df['Sequence_2_clan'].nunique():,}\")\n",
    "\n",
    "# for embeddings, we use \"Sequence_2_ID\" as an identifier of protein sequences\n",
    "assert limit_rpi_df['Raw_ID2'].nunique() == limit_rpi_df['Sequence_2_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique protein sequences: 1,306\n",
      "Number of unique RNA sequences: 4,168\n"
     ]
    }
   ],
   "source": [
    "# Create unique embedding IDs for RNA and protein sequences\n",
    "limit_rpi_df['Sequence_2_emb_ID'] = limit_rpi_df.groupby(['Sequence_2']).ngroup()\n",
    "unique_proteins = limit_rpi_df.drop_duplicates(subset=['Sequence_2_emb_ID'])\n",
    "print(f\"Number of unique protein sequences: {unique_proteins['Sequence_2'].nunique():,}\")\n",
    "unique_proteins.to_parquet(os.path.join(ANNOT_DIR, 'unique_proteins.parquet'), engine='pyarrow')\n",
    "\n",
    "limit_rpi_df['Sequence_1_emb_ID'] = limit_rpi_df.groupby(['Sequence_1']).ngroup()\n",
    "unique_RNA = limit_rpi_df.drop_duplicates(subset=['Sequence_1_emb_ID'])\n",
    "print(f\"Number of unique RNA sequences: {unique_RNA['Sequence_1'].nunique():,}\")\n",
    "unique_RNA.to_parquet(os.path.join(ANNOT_DIR, 'unique_rna.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Negative interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clans per family: 139.53\n",
      "Number of clans with no non-interacting families: 0\n",
      "\n",
      "Average number of families per clan: 1053.83\n",
      "Number of families with no non-interacting clans: 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique RNA families and protein clans\n",
    "unique_rna_families = set(limit_rpi_df['Sequence_1_family'])\n",
    "unique_protein_clans = set(limit_rpi_df['Sequence_2_clan'])\n",
    "unique_protein_categories = set(limit_rpi_df['Category2'])\n",
    "unique_rna_categories = set(limit_rpi_df['Category1'])\n",
    "\n",
    "# Initialize dictionaries\n",
    "non_interacting_clans_per_rna_family = {family: set(unique_protein_clans) for family in unique_rna_families}\n",
    "non_interacting_families_per_protein_clan = {clan: set(unique_rna_families) for clan in unique_protein_clans}\n",
    "interacting_rna_categories_per_clan = {clan: set() for clan in unique_protein_clans} \n",
    "interacting_protein_categories_per_family = {family: set() for family in unique_rna_families}\n",
    "\n",
    "# Precompute clan and family categories\n",
    "clan_categories = {clan: limit_rpi_df[limit_rpi_df['Sequence_2_clan'] == clan]['Category2'].iloc[0] for clan in unique_protein_clans}\n",
    "family_categories = {family: limit_rpi_df[limit_rpi_df['Sequence_1_family'] == family]['Category1'].iloc[0] for family in unique_rna_families}\n",
    "\n",
    "# Update dictionaries by removing interacting pairs\n",
    "for _, row in limit_rpi_df.iterrows():\n",
    "    rna_family = row['Sequence_1_family']\n",
    "    protein_clan = row['Sequence_2_clan']\n",
    "    rna_category = row['Category1']\n",
    "    protein_category = row['Category2']\n",
    "    \n",
    "    if rna_family in non_interacting_clans_per_rna_family and protein_clan in non_interacting_clans_per_rna_family[rna_family]:\n",
    "        non_interacting_clans_per_rna_family[rna_family].remove(protein_clan)\n",
    "        interacting_rna_categories_per_clan[protein_clan].add(rna_category)\n",
    "\n",
    "    if protein_clan in non_interacting_families_per_protein_clan and rna_family in non_interacting_families_per_protein_clan[protein_clan]:\n",
    "        non_interacting_families_per_protein_clan[protein_clan].remove(rna_family)\n",
    "        interacting_protein_categories_per_family[rna_family].add(protein_category)\n",
    "\n",
    "# Convert sets to lists (if required)\n",
    "non_interacting_clans_per_rna_family = {k: list(v) for k, v in non_interacting_clans_per_rna_family.items()}\n",
    "non_interacting_families_per_protein_clan = {k: list(v) for k, v in non_interacting_families_per_protein_clan.items()}\n",
    "\n",
    "# Average of clans per family \n",
    "avg_clans_per_family = sum([len(clans) for clans in non_interacting_clans_per_rna_family.values()])/len(non_interacting_clans_per_rna_family)\n",
    "print(f\"Average number of clans per family: {avg_clans_per_family:.2f}\")\n",
    "\n",
    "# Number of clans with no non-interacting families\n",
    "print(f\"Number of clans with no non-interacting families: {len([clan for clan, families in non_interacting_families_per_protein_clan.items() if len(families) == 0])}\\n\")\n",
    "\n",
    "# Average of families per clan\n",
    "avg_families_per_clan = sum([len(families) for families in non_interacting_families_per_protein_clan.values()])/len(non_interacting_families_per_protein_clan)\n",
    "print(f\"Average number of families per clan: {avg_families_per_clan:.2f}\")\n",
    "\n",
    "# Number of families with no non-interacting clans\n",
    "print(f\"Number of families with no non-interacting clans: {len([family for family, clans in non_interacting_clans_per_rna_family.items() if len(clans) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clans per family: 74.45\n",
      "Number of clans with no non-interacting families: 2\n",
      "\n",
      "Average number of families per clan: 368.82\n",
      "Number of families with no non-interacting clans: 214\n"
     ]
    }
   ],
   "source": [
    "# Create copies of the original dictionaries\n",
    "filtered_clans_per_rna_family = non_interacting_clans_per_rna_family.copy()\n",
    "filtered_families_per_protein_clan = non_interacting_families_per_protein_clan.copy()\n",
    "\n",
    "# Filter non-interacting clans per RNA family using interacting categories\n",
    "for family, clans in filtered_clans_per_rna_family.items():\n",
    "    interacting_categories = interacting_protein_categories_per_family[family]\n",
    "    filtered_clans_per_rna_family[family] = [\n",
    "        clan for clan in clans if clan_categories[clan] not in interacting_categories\n",
    "    ]\n",
    "\n",
    "# Filter non-interacting families per protein clan using interacting categories\n",
    "for clan, families in filtered_families_per_protein_clan.items():\n",
    "    interacting_categories = interacting_rna_categories_per_clan[clan]\n",
    "    filtered_families_per_protein_clan[clan] = [\n",
    "        family for family in families if family_categories[family] not in interacting_categories\n",
    "    ]\n",
    "\n",
    "# Average of clans per family \n",
    "avg_clans_per_family = sum([len(clans) for clans in filtered_clans_per_rna_family.values()])/len(filtered_clans_per_rna_family)\n",
    "print(f\"Average number of clans per family: {avg_clans_per_family:.2f}\")\n",
    "\n",
    "# Number of clans with no non-interacting families\n",
    "print(f\"Number of clans with no non-interacting families: {len([clan for clan, families in filtered_families_per_protein_clan.items() if len(families) == 0]):,}\\n\")\n",
    "\n",
    "# Average of families per clan\n",
    "avg_families_per_clan = sum([len(families) for families in filtered_families_per_protein_clan.values()])/len(filtered_families_per_protein_clan)\n",
    "print(f\"Average number of families per clan: {avg_families_per_clan:.2f}\")\n",
    "\n",
    "# Number of families with no non-interacting clans\n",
    "print(f\"Number of families with no non-interacting clans: {len([family for family, clans in filtered_clans_per_rna_family.items() if len(clans) == 0]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clans per family: 99.09\n",
      "Number of clans with no non-interacting families: 0\n",
      "Average number of families per clan: 374.38\n",
      "\n",
      "Number of families with no non-interacting clans: 0\n"
     ]
    }
   ],
   "source": [
    "# Revert clans with no non-interacting families to the original non-interacting set\n",
    "for clan in filtered_families_per_protein_clan:\n",
    "    if not filtered_families_per_protein_clan[clan]:\n",
    "        filtered_families_per_protein_clan[clan] = non_interacting_families_per_protein_clan[clan]\n",
    "\n",
    "# Revert families with no non-interacting clans to the original non-interacting set\n",
    "for family in filtered_clans_per_rna_family:\n",
    "    if not filtered_clans_per_rna_family[family]:\n",
    "        filtered_clans_per_rna_family[family] = non_interacting_clans_per_rna_family[family]\n",
    "\n",
    "# Average of clans per family \n",
    "avg_clans_per_family = sum([len(clans) for clans in filtered_clans_per_rna_family.values()])/len(filtered_clans_per_rna_family)\n",
    "print(f\"Average number of clans per family: {avg_clans_per_family:.2f}\")\n",
    "\n",
    "# Number of clans with no non-interacting families\n",
    "print(f\"Number of clans with no non-interacting families: {len([clan for clan, families in filtered_families_per_protein_clan.items() if len(families) == 0]):,}\")\n",
    "\n",
    "# Average of families per clan\n",
    "avg_families_per_clan = sum([len(families) for families in filtered_families_per_protein_clan.values()])/len(filtered_families_per_protein_clan)\n",
    "print(f\"Average number of families per clan: {avg_families_per_clan:.2f}\\n\")\n",
    "\n",
    "# Number of families with no non-interacting clans\n",
    "print(f\"Number of families with no non-interacting clans: {len([family for family, clans in filtered_clans_per_rna_family.items() if len(clans) == 0]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_select_protein_from_clan(clan, df):\n",
    "    proteins_in_clan = df[df['Sequence_2_clan'] == clan]\n",
    "    if not proteins_in_clan.empty:\n",
    "        selected_protein = random.choice(proteins_in_clan.to_dict(orient='records'))\n",
    "        return {\n",
    "            'Interactor2.Symbol': selected_protein['Interactor2.Symbol'],\n",
    "            'Category2': selected_protein['Category2'],\n",
    "            'Species2': selected_protein['Species2'],\n",
    "            'Sequence_2': selected_protein['Sequence_2'],\n",
    "            'Sequence_2_ID': selected_protein['Sequence_2_ID'],\n",
    "            'Raw_ID2': selected_protein['Raw_ID2'],\n",
    "            'Sequence_2_clan': selected_protein['Sequence_2_clan'],\n",
    "            'Sequence_2_len': selected_protein['Sequence_2_len'],\n",
    "            'Sequence_2_emb_ID': selected_protein['Sequence_2_emb_ID']\n",
    "        }\n",
    "    else:\n",
    "        return {}\n",
    "    \n",
    "def randomly_select_rna_from_family(family, df):\n",
    "    rnas_in_family = df[df['Sequence_1_family'] == family]\n",
    "    if not rnas_in_family.empty:\n",
    "        selected_rna = random.choice(rnas_in_family.to_dict(orient='records'))\n",
    "        return {\n",
    "            'Interactor1.Symbol': selected_rna['Interactor1.Symbol'],\n",
    "            'Category1': selected_rna['Category1'],\n",
    "            'Species1': selected_rna['Species1'],\n",
    "            'Sequence_1': selected_rna['Sequence_1'],\n",
    "            'Sequence_1_ID': selected_rna['Sequence_1_ID'],\n",
    "            'Raw_ID1': selected_rna['Raw_ID1'],\n",
    "            'Sequence_1_family': selected_rna['Sequence_1_family'],\n",
    "            'Sequence_1_len': selected_rna['Sequence_1_len'],\n",
    "            'Sequence_1_emb_ID': selected_rna['Sequence_1_emb_ID']\n",
    "        }\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Negative Interactions: 100%|██████████| 40739/40739 [06:48<00:00, 99.76it/s] \n"
     ]
    }
   ],
   "source": [
    "# Assuming limit_rpi_df is your original DataFrame\n",
    "negative_interactions = []\n",
    "\n",
    "for _, row in tqdm(limit_rpi_df.iterrows(), total=limit_rpi_df.shape[0], desc=\"Generating Negative Interactions\"):\n",
    "    # Negative interaction based on RNA\n",
    "    rna_family = row['Sequence_1_family']\n",
    "    non_interacting_clans = filtered_clans_per_rna_family.get(rna_family, [])\n",
    "    if non_interacting_clans:\n",
    "        chosen_clan = random.choice(non_interacting_clans)\n",
    "        # Assuming you have a function to randomly select a protein from a clan\n",
    "        chosen_protein = randomly_select_protein_from_clan(chosen_clan, limit_rpi_df)\n",
    "        negative_entry = row.copy()\n",
    "        negative_entry.update(chosen_protein)  # Update the entry with the chosen protein's information\n",
    "        negative_entry['interaction'] = False\n",
    "        negative_entry['RNAInterID'] = f\"N_{row['RNAInterID']}\"\n",
    "        negative_interactions.append(negative_entry)\n",
    "\n",
    "    # Negative interaction based on Protein\n",
    "    protein_clan = row['Sequence_2_clan']\n",
    "    non_interacting_families = filtered_families_per_protein_clan.get(protein_clan, [])\n",
    "    if non_interacting_families:\n",
    "        chosen_family = random.choice(non_interacting_families)\n",
    "        # Assuming you have a function to randomly select an RNA from a family\n",
    "        chosen_rna = randomly_select_rna_from_family(chosen_family, limit_rpi_df)\n",
    "        negative_entry = row.copy()\n",
    "        negative_entry.update(chosen_rna)  # Update the entry with the chosen RNA's information\n",
    "        negative_entry['interaction'] = False\n",
    "        negative_entry['RNAInterID'] = f\"N_{row['RNAInterID']}\"\n",
    "        negative_interactions.append(negative_entry)\n",
    "\n",
    "# Convert the list of negative interactions to a DataFrame\n",
    "negative_interactions_df = pd.DataFrame(negative_interactions)\n",
    "\n",
    "# Concatenate the original DataFrame with the negative interactions DataFrame\n",
    "all_interactions_df = pd.concat([limit_rpi_df, negative_interactions_df], ignore_index=True)\n",
    "all_interactions_df.to_parquet(os.path.join(INTER_DIR, 'all_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative interactions: 81,478\n",
      "Number of positive interactions: 40,739\n"
     ]
    }
   ],
   "source": [
    "# Quick analysis of the dataset\n",
    "print(f\"Number of negative interactions: {all_interactions_df[all_interactions_df['interaction'] == False].shape[0]:,}\")\n",
    "print(f\"Number of positive interactions: {all_interactions_df[all_interactions_df['interaction'] == True].shape[0]:,}\")\n",
    "\n",
    "assert all_interactions_df.shape[0] == limit_rpi_df.shape[0] + negative_interactions_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 97773 -- 80.0%     -- 1148 unique RNA families\n",
      "Test set size: 24444 -- 20.0%     -- 1144 unique RNA families\n",
      "Number of negative interactions in the train set: 65,175\n",
      "Number of positive interactions in the train set: 32,598\n",
      "\n",
      "Number of negative interactions in the test set: 16,303\n",
      "Number of positive interactions in the test set: 8,141 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "all_interactions_df = pd.read_parquet(os.path.join(INTER_DIR, 'all_interactions.parquet'), engine='pyarrow')\n",
    "\n",
    "# Shuffle and Split randomly all_interactions_df in [0.8, 0.2] sets \n",
    "all_interactions_df = all_interactions_df.sample(frac=1, random_state=5555).reset_index(drop=True)\n",
    "split_index = int(all_interactions_df.shape[0] * (1 - TEST_SET_SIZE))\n",
    "train_df = all_interactions_df.iloc[:split_index]\n",
    "test_df = all_interactions_df.iloc[split_index:]\n",
    "\n",
    "# Save train and test DataFrames\n",
    "train_df.to_parquet(os.path.join(INTER_DIR, 'r_train_set.parquet'), engine='pyarrow')\n",
    "test_df.to_parquet(os.path.join(INTER_DIR, 'r_test_set.parquet'), engine='pyarrow')\n",
    "\n",
    "train_families = train_df['Sequence_1_family'].nunique()\n",
    "test_families = test_df['Sequence_1_family'].nunique()\n",
    "\n",
    "print(f\"Training set size: {len(train_df)} -- {round(train_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "    -- {train_families} unique RNA families\")\n",
    "print(f\"Test set size: {len(test_df)} -- {round(test_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "    -- {test_families} unique RNA families\")\n",
    "\n",
    "print(f\"Number of negative interactions in the train set: {train_df[train_df['interaction'] == False].shape[0]:,}\")\n",
    "print(f\"Number of positive interactions in the train set: {train_df[train_df['interaction'] == True].shape[0]:,}\\n\")\n",
    "print(f\"Number of negative interactions in the test set: {test_df[test_df['interaction'] == False].shape[0]:,}\")\n",
    "print(f\"Number of positive interactions in the test set: {test_df[test_df['interaction'] == True].shape[0]:,} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_rna_families(all_interactions_df, test_set_fraction, validation_set_fraction):\n",
    "    unique_rna_families = all_interactions_df['Sequence_1_family'].unique()\n",
    "    np.random.shuffle(unique_rna_families)\n",
    "\n",
    "    num_families = len(unique_rna_families)\n",
    "    num_test_families = int(num_families * test_set_fraction)\n",
    "    num_validation_families = int(num_families * validation_set_fraction)\n",
    "\n",
    "    test_families = unique_rna_families[:num_test_families]\n",
    "    validation_families = unique_rna_families[num_test_families:num_test_families + num_validation_families]\n",
    "    train_families = unique_rna_families[num_test_families + num_validation_families:]\n",
    "\n",
    "    return train_families, validation_families, test_families\n",
    "\n",
    "\n",
    "def create_train_validation_test_sets(interactions_file, output_dir, test_set_fraction=0.10, validation_set_fraction=0.10):\n",
    "    all_interactions_df = pd.read_parquet(interactions_file, engine='pyarrow')\n",
    "\n",
    "    # Split RNA families into training, validation, and test sets\n",
    "    train_families, validation_families, test_families = split_rna_families(all_interactions_df, test_set_fraction, validation_set_fraction)\n",
    "\n",
    "    # Create the corresponding datasets\n",
    "    train_df = all_interactions_df[all_interactions_df['Sequence_1_family'].isin(train_families)]\n",
    "    validation_df = all_interactions_df[all_interactions_df['Sequence_1_family'].isin(validation_families)]\n",
    "    test_df = all_interactions_df[all_interactions_df['Sequence_1_family'].isin(test_families)]\n",
    "    \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "def check_rna_families(train_df, validation_df, test_df):\n",
    "    # Extract RNA families from each set\n",
    "    train_families = set(train_df['Sequence_1_family'].unique())\n",
    "    validation_families = set(validation_df['Sequence_1_family'].unique())\n",
    "    test_families = set(test_df['Sequence_1_family'].unique())\n",
    "\n",
    "    # Check for overlaps\n",
    "    train_validation_overlap = train_families.intersection(validation_families)\n",
    "    train_test_overlap = train_families.intersection(test_families)\n",
    "\n",
    "    print(f\"Training set size: {len(train_df)} -- {round(train_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "      -- {len(train_families)} unique RNA families\")\n",
    "    print(f\"Test set size: {len(test_df)} -- {round(test_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "        -- {len(test_families)} unique RNA families\")\n",
    "    print(f\"Validation set size: {len(validation_df)} -- {round(validation_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "        -- {len(validation_families)} unique RNA families\")\n",
    "    \n",
    "    if not train_validation_overlap and not train_test_overlap:\n",
    "        print(\"Validation and test sets contain RNA families not present in the training set. \\n\")\n",
    "        return True\n",
    "    else:\n",
    "        if train_validation_overlap:\n",
    "            print(f\"Overlap between training and validation sets: {train_validation_overlap} \\n\")\n",
    "            return False\n",
    "        if train_test_overlap:\n",
    "            print(f\"Overlap between training and test sets: {train_test_overlap} \\n\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 93564 -- 76.56%       -- 804 unique RNA families\n",
      "Test set size: 13003 -- 10.64%         -- 172 unique RNA families\n",
      "Validation set size: 15650 -- 12.81%         -- 172 unique RNA families\n",
      "Validation and test sets contain RNA families not present in the training set. \n",
      "\n",
      "Number of negative interactions in the train set: 64,006\n",
      "Number of positive interactions in the train set: 29,558\n",
      "\n",
      "Number of negative interactions in the test set: 8,116\n",
      "Number of positive interactions in the test set: 4,887 \n",
      "\n",
      "Number of negative interactions in the validation set: 9,356\n",
      "Number of positive interactions in the validation set: 6,294\n"
     ]
    }
   ],
   "source": [
    "all_interactions_path = os.path.join(INTER_DIR, 'all_interactions.parquet')\n",
    "\n",
    "# Create train and test sets\n",
    "train_df, validation_df, test_df = create_train_validation_test_sets(all_interactions_path, INTER_DIR, 0.15, 0.15)\n",
    "\n",
    "if check_rna_families(train_df, validation_df, test_df):\n",
    "    # Save the Data\n",
    "    train_df.to_parquet(os.path.join(INTER_DIR, 'train_set.parquet'), engine='pyarrow')\n",
    "    validation_df.to_parquet(os.path.join(INTER_DIR, 'validation_set.parquet'), engine='pyarrow')\n",
    "    test_df.to_parquet(os.path.join(INTER_DIR, 'test_set.parquet'), engine='pyarrow')\n",
    "\n",
    "    # check how many positive and negative samples in each set\n",
    "    print(f\"Number of negative interactions in the train set: {train_df[train_df['interaction'] == False].shape[0]:,}\")\n",
    "    print(f\"Number of positive interactions in the train set: {train_df[train_df['interaction'] == True].shape[0]:,}\\n\")\n",
    "    print(f\"Number of negative interactions in the test set: {test_df[test_df['interaction'] == False].shape[0]:,}\")\n",
    "    print(f\"Number of positive interactions in the test set: {test_df[test_df['interaction'] == True].shape[0]:,} \\n\")\n",
    "    print(f\"Number of negative interactions in the validation set: {validation_df[validation_df['interaction'] == False].shape[0]:,}\")\n",
    "    print(f\"Number of positive interactions in the validation set: {validation_df[validation_df['interaction'] == True].shape[0]:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset comprising of train and val sets\n",
    "train_val_df = pd.concat([train_df, validation_df], ignore_index=True)\n",
    "train_val_df.to_parquet(os.path.join(INTER_DIR, 'train_val_set.parquet'), engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
