{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import choice\n",
    "from pathlib import Path\n",
    "\n",
    "# src_dir = Path.cwd().parent\n",
    "# sys.path.append(str(src_dir))\n",
    "from utils import load_rna_inter_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset Creation\n",
    "This dataset helps to create our final dataset with the given splits (Training Set, Test Set, Random Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = \"/work/dlclarge1/matusd-rpi/RPI/\" # change this to your working directory\n",
    "ANNOT_DIR = \"data/annotations/\"\n",
    "INTER_DIR = \"data/interactions/\"\n",
    "EMB_DIR = \"data/embeddings/\"\n",
    "RNAINTER_DIR = \"data/RNAInter/\"\n",
    "\n",
    "os.chdir(WORKING_DIR)\n",
    "\n",
    "if not os.path.exists(INTER_DIR):\n",
    "    os.makedirs(INTER_DIR)\n",
    "    \n",
    "if not os.path.exists(EMB_DIR):\n",
    "    os.makedirs(EMB_DIR)\n",
    "    \n",
    "# limit on number of interactions per protein/RNA\n",
    "PROTEIN_INTER = 150\n",
    "RNA_INTER = 150\n",
    "\n",
    "TEST_SET_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RNAInter DB with interaction data\n",
    "\n",
    "# Create directory\n",
    "if not os.path.exists(RNAINTER_DIR):\n",
    "    os.makedirs(RNAINTER_DIR)\n",
    "\n",
    "rnainter_path = RNAINTER_DIR + \"Download_data_RP.txt\"\n",
    "\n",
    "# Download data\n",
    "if not os.path.exists(rnainter_path):\n",
    "    os.chdir(RNAINTER_DIR)\n",
    "\n",
    "    !wget http://www.rnainter.org/raidMedia/download/Download_data_RP.tar.gz\n",
    "    !tar -xf Download_data_RP.tar.gz\n",
    "    !rm Download_data_RP.tar.gz\n",
    "\n",
    "    os.chdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of RNA sequences: 7,847\n",
      "Number of protein sequences: 26,575\n"
     ]
    }
   ],
   "source": [
    "# Prepare RNA sequences DataFrame\n",
    "rna_sequences = pd.read_parquet(os.path.join(ANNOT_DIR, 'rna_short_families.parquet'), engine='pyarrow')\n",
    "\n",
    "# Drop entries lacking crucial information or duplicated\n",
    "rna_sequences = rna_sequences.dropna(subset=['Sequence_1', 'Raw_ID1', 'Sequence_1_family'])\n",
    "rna_sequences = rna_sequences.drop_duplicates(subset=['Raw_ID1'])\n",
    "\n",
    "print(f\"Number of RNA sequences: {rna_sequences.shape[0]:,}\")\n",
    "\n",
    "# Prepare protein sequences DataFrame\n",
    "protein_sequences = pd.read_parquet(os.path.join(ANNOT_DIR, 'proteins_short_clans.parquet'), engine='pyarrow')\n",
    "\n",
    "# Drop entries lacking crucial information or duplicated\n",
    "protein_sequences = protein_sequences.dropna(subset=['Sequence_2', 'Raw_ID2', 'Sequence_2_clan'])\n",
    "protein_sequences= protein_sequences.drop_duplicates(subset=['Raw_ID2'])\n",
    "\n",
    "print(f\"Number of protein sequences: {protein_sequences.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load raw RNAInter database\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rna_inter_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_rna_inter_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnainter_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of interactions in RNAInter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrna_inter_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/dlclarge1/matusd-rpi/RPI/dataset/utils.py:81\u001b[0m, in \u001b[0;36mload_rna_inter_csv\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mLoads the RNA Inter CSV file and returns a DataFrame with specified columns.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNAInterID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInteractor1.Symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     80\u001b[0m }\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1075\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1165\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/rpi/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load raw RNAInter database\n",
    "rna_inter_df = load_rna_inter_csv(rnainter_path)\n",
    "print(f\"Number of interactions in RNAInter: {rna_inter_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA categories:\n",
      "['lncRNA' 'mRNA' 'nonsense_mediated_decay' 'retained_intron' 'unknown'\n",
      " 'others' 'rRNA' 'pseudo' 'ncRNA' 'piRNA' 'TEC' 'circRNA' 'miRNA' 'snRNA'\n",
      " 'snoRNA' 'non_stop_decay' 'tRNA' 'sncRNA' 'scRNA' 'ribozyme' 'sRNA'\n",
      " 'miscRNA' 'scaRNA' 'unassigned RNA' 'Category1' 'Mt_tRNA' 'misc_RNA'\n",
      " 'vtRNAs']\n"
     ]
    }
   ],
   "source": [
    "# print all rna categories\n",
    "print(\"RNA categories:\")\n",
    "print(rna_inter_df['Category1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (positive) interactions with annotated entries: 488,184 \n",
      "\n",
      "RPI dataframe columns: \n",
      " ['RNAInterID', 'Interactor1.Symbol', 'Category1', 'Species1', 'Interactor2.Symbol', 'Category2', 'Species2', 'Raw_ID1', 'Raw_ID2', 'score', 'strong', 'weak', 'predict', 'Sequence_1_rfam_q_accession', 'Sequence_1_family', 'Sequence_1_rfam_t_accession', 'Sequence_1_rfam_description', 'Sequence_1_rfam_e_value', 'Sequence_1', 'Sequence_1_len', 'Sequence_1_ID', 'Sequence_2_clan', 'Sequence_2_ID', 'Sequence_2', 'Sequence_2_len', 'interaction'] \n",
      "\n",
      "RPI sample entries: \n",
      "    RNAInterID Interactor1.Symbol Category1      Species1 Interactor2.Symbol Category2      Species2         Raw_ID1     Raw_ID2   score strong       weak                                    predict Sequence_1_rfam_q_accession Sequence_1_family Sequence_1_rfam_t_accession              Sequence_1_rfam_description  Sequence_1_rfam_e_value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Sequence_1  Sequence_1_len Sequence_1_ID Sequence_2_clan Sequence_2_ID                                                                                                                                                                                                                                     Sequence_2  Sequence_2_len  interaction\n",
      "0  RP34117562      2010103J01Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus      NCBI:69889  NCBI:56758  0.1229    NaN        NaN  Scan pipeline widely used MATCH algorithm                           -           mir-192                     RF00130           mir-192/215 microRNA precursor             1.100000e-16                                                                                                                                                                                                                                                    ACUCAGGACUUCCAGGUAAGGAGCCGCUGCUGUCCUCUUGGUCCUCUGUUCUCUCUUUAUAAGCAAAAGGCACAGGACAGGAUCUCUGCUGGAAGUGACCGUGGAAAGAACGAGUUCAAGUGCUAGGUCAGCAGAGGACCCAGCCAUGGAGACUACGGAGCACGGAGCUCUCAGCAUCAACGGUGUACAGGAGAAUGACCUAUGAUUUGACAGACCGUGCAGCUGUGUAUGUCUGUCAUUCUGUAGGCCAAUAUUCUGUAUGUCACUGCUACUUAAAAUCCGGACAUCGGCAAACACCCUCUGAGCGCUGUGCAGCAGAUCACGGGAGAGUCUGUAGCAUGGCAGGAGAAUGUGCUGACAAAAUAAAAUGAGUGCUUCUGUGUA             384    1907071096          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n",
      "1  RP34118868      2310002D06Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus      NCBI:69522  NCBI:56758  0.1229    NaN        NaN  Scan pipeline widely used MATCH algorithm                           -                U3                     RF00012                   Small nucleolar RNA U3             9.900000e-07                                                                                                                        AGAUUCUGCUUGCUGUAGCCAAUAAGCACAACAGCUUGGAAGCAAUGCUGCAGGCAGCCGGCACCCUCACUGUGCAGCUGAGAAAACUGAGGCUGAGAAUUGACCGGAGCCACCUCAUAGAUGGCUUCAUUCGCAAGCCUGACCUGUCUUGGAUUUUCCGAAGAGUCAACCUACCUGACAUCAUCCAAAAAGCACCACCCUGUCCACUCUGCUCCUGGCAUUUAAGAUCCUCCAGUAUCUAGACUUGCCCAGUCUGGCCAGUCUCAACUCACACCAGGUCUUUGCCAGUAUCCAGCAUGCUCUCAUGAGAUAUUAUCCUGAGGGCCUUGGCUGUCCCUGCCCUUUCCUUAUUCUUCUCUUCCUUUUUGGGAUUACCCUCCUAUUCUCCAGAUUUAUCCACUUUCUCUGGGAAGCCUUCCUAAAGACCACUUUGCAAGACUAUACUUUCAGGAAUCAUUUCUGUAGUUCGUUACUGAAGACCAGUUUGCAAUAAAUUAUUUCUUCCUCC             508     356460946          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n",
      "2  RP09023616      5430416N02Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus  NCBI:100503199  NCBI:56758  0.1229    NaN  HITS-CLIP  Scan pipeline widely used MATCH algorithm                           -         adapt33_3                     RF02257  Adaptive response 33 conserved region 3             9.600000e-27  CCGUGGGCACGUUCUCGCUUCCAUUCGGUCCUCCUUUUGUUAACGCUCUGGCAUCAUGUCUACGCCAGCUCCCGCGCAAUCCGGCGCCAUCGCGCUUUGGGCGAGCAUGGCCAUGGGGAGUAGAGAGGUGGAAACCGAGCUGACGCCUGCCUGACCCUGGCGAUGGUGGCGCGCGCCGGGAAGGACUGAUUGGAGAAUGGCGCCAAAUGGGUCACGGAUGGCGAGGGGGCACAGGAGCUCUCGAUGUGACCUGGCGCUGUGGAUGUGAUGCACAGCAGCUUGAGUGGGACUGCUCCGCUGUCCUCAUGAGAGAACGCUUUUUCUGAAGAUGGGAGGUGGCUAAUGAAAGAAGGAAUUGUGUUCUCGGUGAUGCCUGGAAGAGAUGCGUGACGUUGGAAGAUGAUUACGAAAUACAGGAAAGGAAUGAAAUCAAAGGAUGUUUUUUGUAAGAGUAACACUUACAGAAAUAUUCAUUAAUUUGAAGAUUUAUAUAAGGCCUGGUGACCUCCGUUAAUUCCUGGGACCCACAGUGUGGAAGAAGAGACCUGACUCCUGAAAGUUGUCUUCUGACCACAUAUACACAAUAUGUAAAUAAAUGUAAUUAAAAAAUCAAAAUAGUAAAACUG             626     300360574          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n"
     ]
    }
   ],
   "source": [
    "# Merge RNAInter and sequences DataFrames\n",
    "rpi_df = rna_inter_df.merge(rna_sequences, on='Raw_ID1', how='inner').merge(protein_sequences, on='Raw_ID2', how='inner')\n",
    "\n",
    "# Create interaction label for classification\n",
    "rpi_df['interaction'] = True\n",
    "\n",
    "print(f\"Number of (positive) interactions with annotated entries: {rpi_df.shape[0]:,} \\n\")\n",
    "print(f\"RPI dataframe columns: \\n {rpi_df.columns.to_list()} \\n\")\n",
    "print(f\"RPI sample entries: \\n {rpi_df.head(3).to_string()}\")\n",
    "\n",
    "# Save RPI DataFrame\n",
    "rpi_df.to_parquet(os.path.join(INTER_DIR, 'raw_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid RNA interactors removed: \n",
      " Category1\n",
      "mRNA                       25010\n",
      "retained_intron              128\n",
      "nonsense_mediated_decay       41\n",
      "unknown                       17\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Number of interactions with valid RNA interactors: 462,988 \n",
      "\n",
      "Invalid protein interactors removed: \n",
      " Series([], Name: count, dtype: int64) \n",
      "\n",
      "Number of interactions with valid protein interactors: 462,988 \n",
      "\n",
      "Number of interactions after removing duplicates: 462,947\n",
      "Number of interactions after limiting number of interactions per protein/RNA: 40,744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpi_df = pd.read_parquet(os.path.join(INTER_DIR, 'raw_interactions.parquet'), engine='pyarrow')\n",
    "\n",
    "# Remove invalid RNA interactors\n",
    "# (we remove all mRNAs as the RNA-FM model has been trained only on ncRNAs)\n",
    "valid_rna = ['lncRNA', 'snRNA', 'snoRNA', 'scaRNA', 'miRNA', 'circRNA', 'rRNA',\n",
    "       'ribozyme', 'sncRNA', 'misc_RNA', 'ncRNA', 'sRNA', 'Mt_tRNA', 'vtRNAs',\n",
    "       'pseudo', 'others']\n",
    "print(f\"Invalid RNA interactors removed: \\n {rpi_df[~rpi_df['Category1'].isin(valid_rna)]['Category1'].value_counts()} \\n\")\n",
    "rpi_df = rpi_df[rpi_df['Category1'].isin(valid_rna)]\n",
    "print(f\"Number of interactions with valid RNA interactors: {rpi_df.shape[0]:,} \\n\")\n",
    "\n",
    "# Remove invalid protein interactors\n",
    "valid_protein = ['TF', 'RBP', 'protein']\n",
    "print(f\"Invalid protein interactors removed: \\n {rpi_df[~rpi_df['Category2'].isin(valid_protein)]['Category2'].value_counts()} \\n\")\n",
    "rpi_df = rpi_df[rpi_df['Category2'].isin(valid_protein)]\n",
    "print(f\"Number of interactions with valid protein interactors: {rpi_df.shape[0]:,} \\n\")\n",
    "\n",
    "# Remove interactions with more than one occurence and with duplicated both interactors\n",
    "rpi_df = rpi_df.drop_duplicates(subset=['RNAInterID'])\n",
    "rpi_df = rpi_df.drop_duplicates(subset=['Raw_ID1', 'Raw_ID2'])\n",
    "print(f\"Number of interactions after removing duplicates: {rpi_df.shape[0]:,}\")\n",
    "\n",
    "# Limit number of interactions per protein/RNA\n",
    "limit_rpi_df = rpi_df.groupby(by=['Raw_ID1']).filter(lambda x: len(x) < RNA_INTER)\n",
    "limit_rpi_df = limit_rpi_df.groupby(by=['Raw_ID2']).filter(lambda x: len(x) < PROTEIN_INTER)\n",
    "print(f\"Number of interactions after limiting number of interactions per protein/RNA: {limit_rpi_df.shape[0]:,} \\n\")\n",
    "limit_rpi_df.to_parquet(os.path.join(INTER_DIR, 'limited_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique RNA sequences: 4,169\n",
      "Number of RNA families: 1,148 \n",
      "\n",
      "Number of unique protein sequences: 1,308\n",
      "Number of protein clans: 152\n"
     ]
    }
   ],
   "source": [
    "# Quick data analysis\n",
    "print(f\"Number of unique RNA sequences: {limit_rpi_df['Sequence_1'].nunique():,}\")\n",
    "print(f\"Number of RNA families: {limit_rpi_df['Sequence_1_family'].nunique():,} \\n\")\n",
    "\n",
    "# for embeddings, we use \"Sequence_1_ID\" as an identifier of RNA sequences\n",
    "assert limit_rpi_df['Raw_ID1'].nunique() == limit_rpi_df['Sequence_1_ID'].nunique()\n",
    "\n",
    "print(f\"Number of unique protein sequences: {limit_rpi_df['Sequence_2'].nunique():,}\")\n",
    "print(f\"Number of protein clans: {limit_rpi_df['Sequence_2_clan'].nunique():,}\")\n",
    "\n",
    "# for embeddings, we use \"Sequence_2_ID\" as an identifier of protein sequences\n",
    "assert limit_rpi_df['Raw_ID2'].nunique() == limit_rpi_df['Sequence_2_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique protein sequences: 1,308\n",
      "Number of unique RNA sequences: 4,169\n"
     ]
    }
   ],
   "source": [
    "# Create unique embedding IDs for RNA and protein sequences\n",
    "limit_rpi_df['Sequence_2_emb_ID'] = limit_rpi_df.groupby(['Sequence_2']).ngroup()\n",
    "unique_proteins = limit_rpi_df.drop_duplicates(subset=['Sequence_2_emb_ID'])\n",
    "print(f\"Number of unique protein sequences: {unique_proteins['Sequence_2'].nunique():,}\")\n",
    "unique_proteins.to_parquet(os.path.join(ANNOT_DIR, 'unique_proteins.parquet'), engine='pyarrow')\n",
    "\n",
    "limit_rpi_df['Sequence_1_emb_ID'] = limit_rpi_df.groupby(['Sequence_1']).ngroup()\n",
    "unique_RNA = limit_rpi_df.drop_duplicates(subset=['Sequence_1_emb_ID'])\n",
    "print(f\"Number of unique RNA sequences: {unique_RNA['Sequence_1'].nunique():,}\")\n",
    "unique_RNA.to_parquet(os.path.join(ANNOT_DIR, 'unique_rna.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Negative interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clans per family: 139.53\n",
      "Number of clans with no non-interacting families: 0\n",
      "\n",
      "Average number of families per clan: 1053.83\n",
      "Number of families with no non-interacting clans: 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique RNA families and protein clans\n",
    "unique_rna_families = set(limit_rpi_df['Sequence_1_family'])\n",
    "unique_protein_clans = set(limit_rpi_df['Sequence_2_clan'])\n",
    "unique_protein_categories = set(limit_rpi_df['Category2'])\n",
    "unique_rna_categories = set(limit_rpi_df['Category1'])\n",
    "\n",
    "# Initialize dictionaries\n",
    "non_interacting_clans_per_rna_family = {family: set(unique_protein_clans) for family in unique_rna_families}\n",
    "non_interacting_families_per_protein_clan = {clan: set(unique_rna_families) for clan in unique_protein_clans}\n",
    "interacting_rna_categories_per_clan = {clan: set() for clan in unique_protein_clans} \n",
    "interacting_protein_categories_per_family = {family: set() for family in unique_rna_families}\n",
    "\n",
    "# Precompute clan and family categories\n",
    "clan_categories = {clan: limit_rpi_df[limit_rpi_df['Sequence_2_clan'] == clan]['Category2'].iloc[0] for clan in unique_protein_clans}\n",
    "family_categories = {family: limit_rpi_df[limit_rpi_df['Sequence_1_family'] == family]['Category1'].iloc[0] for family in unique_rna_families}\n",
    "\n",
    "# Update dictionaries by removing interacting pairs\n",
    "for _, row in limit_rpi_df.iterrows():\n",
    "    rna_family = row['Sequence_1_family']\n",
    "    protein_clan = row['Sequence_2_clan']\n",
    "    rna_category = row['Category1']\n",
    "    protein_category = row['Category2']\n",
    "    \n",
    "    if rna_family in non_interacting_clans_per_rna_family and protein_clan in non_interacting_clans_per_rna_family[rna_family]:\n",
    "        non_interacting_clans_per_rna_family[rna_family].remove(protein_clan)\n",
    "        interacting_rna_categories_per_clan[protein_clan].add(rna_category)\n",
    "\n",
    "    if protein_clan in non_interacting_families_per_protein_clan and rna_family in non_interacting_families_per_protein_clan[protein_clan]:\n",
    "        non_interacting_families_per_protein_clan[protein_clan].remove(rna_family)\n",
    "        interacting_protein_categories_per_family[rna_family].add(protein_category)\n",
    "\n",
    "# Convert sets to lists (if required)\n",
    "non_interacting_clans_per_rna_family = {k: list(v) for k, v in non_interacting_clans_per_rna_family.items()}\n",
    "non_interacting_families_per_protein_clan = {k: list(v) for k, v in non_interacting_families_per_protein_clan.items()}\n",
    "\n",
    "# Average of clans per family \n",
    "avg_clans_per_family = sum([len(clans) for clans in non_interacting_clans_per_rna_family.values()])/len(non_interacting_clans_per_rna_family)\n",
    "print(f\"Average number of clans per family: {avg_clans_per_family:.2f}\")\n",
    "\n",
    "# Number of clans with no non-interacting families\n",
    "print(f\"Number of clans with no non-interacting families: {len([clan for clan, families in non_interacting_families_per_protein_clan.items() if len(families) == 0])}\\n\")\n",
    "\n",
    "# Average of families per clan\n",
    "avg_families_per_clan = sum([len(families) for families in non_interacting_families_per_protein_clan.values()])/len(non_interacting_families_per_protein_clan)\n",
    "print(f\"Average number of families per clan: {avg_families_per_clan:.2f}\")\n",
    "\n",
    "# Number of families with no non-interacting clans\n",
    "print(f\"Number of families with no non-interacting clans: {len([family for family, clans in non_interacting_clans_per_rna_family.items() if len(clans) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clans per family: 74.45\n",
      "Number of clans with no non-interacting families: 2\n",
      "\n",
      "Average number of families per clan: 368.82\n",
      "Number of families with no non-interacting clans: 214\n"
     ]
    }
   ],
   "source": [
    "# Create copies of the original dictionaries\n",
    "filtered_clans_per_rna_family = non_interacting_clans_per_rna_family.copy()\n",
    "filtered_families_per_protein_clan = non_interacting_families_per_protein_clan.copy()\n",
    "\n",
    "# Filter non-interacting clans per RNA family using interacting categories\n",
    "for family, clans in filtered_clans_per_rna_family.items():\n",
    "    interacting_categories = interacting_protein_categories_per_family[family]\n",
    "    filtered_clans_per_rna_family[family] = [\n",
    "        clan for clan in clans if clan_categories[clan] not in interacting_categories\n",
    "    ]\n",
    "\n",
    "# Filter non-interacting families per protein clan using interacting categories\n",
    "for clan, families in filtered_families_per_protein_clan.items():\n",
    "    interacting_categories = interacting_rna_categories_per_clan[clan]\n",
    "    filtered_families_per_protein_clan[clan] = [\n",
    "        family for family in families if family_categories[family] not in interacting_categories\n",
    "    ]\n",
    "\n",
    "# Average of clans per family \n",
    "avg_clans_per_family = sum([len(clans) for clans in filtered_clans_per_rna_family.values()])/len(filtered_clans_per_rna_family)\n",
    "print(f\"Average number of clans per family: {avg_clans_per_family:.2f}\")\n",
    "\n",
    "# Number of clans with no non-interacting families\n",
    "print(f\"Number of clans with no non-interacting families: {len([clan for clan, families in filtered_families_per_protein_clan.items() if len(families) == 0]):,}\\n\")\n",
    "\n",
    "# Average of families per clan\n",
    "avg_families_per_clan = sum([len(families) for families in filtered_families_per_protein_clan.values()])/len(filtered_families_per_protein_clan)\n",
    "print(f\"Average number of families per clan: {avg_families_per_clan:.2f}\")\n",
    "\n",
    "# Number of families with no non-interacting clans\n",
    "print(f\"Number of families with no non-interacting clans: {len([family for family, clans in filtered_clans_per_rna_family.items() if len(clans) == 0]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clans per family: 99.09\n",
      "Number of clans with no non-interacting families: 0\n",
      "Average number of families per clan: 374.38\n",
      "\n",
      "Number of families with no non-interacting clans: 0\n"
     ]
    }
   ],
   "source": [
    "# Revert clans with no non-interacting families to the original non-interacting set\n",
    "for clan in filtered_families_per_protein_clan:\n",
    "    if not filtered_families_per_protein_clan[clan]:\n",
    "        filtered_families_per_protein_clan[clan] = non_interacting_families_per_protein_clan[clan]\n",
    "\n",
    "# Revert families with no non-interacting clans to the original non-interacting set\n",
    "for family in filtered_clans_per_rna_family:\n",
    "    if not filtered_clans_per_rna_family[family]:\n",
    "        filtered_clans_per_rna_family[family] = non_interacting_clans_per_rna_family[family]\n",
    "\n",
    "# Average of clans per family \n",
    "avg_clans_per_family = sum([len(clans) for clans in filtered_clans_per_rna_family.values()])/len(filtered_clans_per_rna_family)\n",
    "print(f\"Average number of clans per family: {avg_clans_per_family:.2f}\")\n",
    "\n",
    "# Number of clans with no non-interacting families\n",
    "print(f\"Number of clans with no non-interacting families: {len([clan for clan, families in filtered_families_per_protein_clan.items() if len(families) == 0]):,}\")\n",
    "\n",
    "# Average of families per clan\n",
    "avg_families_per_clan = sum([len(families) for families in filtered_families_per_protein_clan.values()])/len(filtered_families_per_protein_clan)\n",
    "print(f\"Average number of families per clan: {avg_families_per_clan:.2f}\\n\")\n",
    "\n",
    "# Number of families with no non-interacting clans\n",
    "print(f\"Number of families with no non-interacting clans: {len([family for family, clans in filtered_clans_per_rna_family.items() if len(clans) == 0]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_select_protein_from_clan(clan, df):\n",
    "    proteins_in_clan = df[df['Sequence_2_clan'] == clan]\n",
    "    if not proteins_in_clan.empty:\n",
    "        selected_protein = random.choice(proteins_in_clan.to_dict(orient='records'))\n",
    "        return {\n",
    "            'Interactor2.Symbol': selected_protein['Interactor2.Symbol'],\n",
    "            'Category2': selected_protein['Category2'],\n",
    "            'Species2': selected_protein['Species2'],\n",
    "            'Sequence_2': selected_protein['Sequence_2'],\n",
    "            'Sequence_2_ID': selected_protein['Sequence_2_ID'],\n",
    "            'Raw_ID2': selected_protein['Raw_ID2'],\n",
    "            'Sequence_2_clan': selected_protein['Sequence_2_clan'],\n",
    "            'Sequence_2_len': selected_protein['Sequence_2_len'],\n",
    "            'Sequence_2_emb_ID': selected_protein['Sequence_2_emb_ID']\n",
    "        }\n",
    "    else:\n",
    "        return {}\n",
    "    \n",
    "def randomly_select_rna_from_family(family, df):\n",
    "    rnas_in_family = df[df['Sequence_1_family'] == family]\n",
    "    if not rnas_in_family.empty:\n",
    "        selected_rna = random.choice(rnas_in_family.to_dict(orient='records'))\n",
    "        return {\n",
    "            'Interactor1.Symbol': selected_rna['Interactor1.Symbol'],\n",
    "            'Category1': selected_rna['Category1'],\n",
    "            'Species1': selected_rna['Species1'],\n",
    "            'Sequence_1': selected_rna['Sequence_1'],\n",
    "            'Sequence_1_ID': selected_rna['Sequence_1_ID'],\n",
    "            'Raw_ID1': selected_rna['Raw_ID1'],\n",
    "            'Sequence_1_family': selected_rna['Sequence_1_family'],\n",
    "            'Sequence_1_len': selected_rna['Sequence_1_len'],\n",
    "            'Sequence_1_emb_ID': selected_rna['Sequence_1_emb_ID']\n",
    "        }\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Negative Interactions: 100%|██████████| 40744/40744 [06:48<00:00, 99.71it/s] \n"
     ]
    }
   ],
   "source": [
    "# Assuming limit_rpi_df is your original DataFrame\n",
    "negative_interactions = []\n",
    "\n",
    "for _, row in tqdm(limit_rpi_df.iterrows(), total=limit_rpi_df.shape[0], desc=\"Generating Negative Interactions\"):\n",
    "    # Negative interaction based on RNA\n",
    "    rna_family = row['Sequence_1_family']\n",
    "    non_interacting_clans = filtered_clans_per_rna_family.get(rna_family, [])\n",
    "    if non_interacting_clans:\n",
    "        chosen_clan = random.choice(non_interacting_clans)\n",
    "        # Assuming you have a function to randomly select a protein from a clan\n",
    "        chosen_protein = randomly_select_protein_from_clan(chosen_clan, limit_rpi_df)\n",
    "        negative_entry = row.copy()\n",
    "        negative_entry.update(chosen_protein)  # Update the entry with the chosen protein's information\n",
    "        negative_entry['interaction'] = False\n",
    "        negative_entry['RNAInterID'] = f\"N_{row['RNAInterID']}\"\n",
    "        negative_interactions.append(negative_entry)\n",
    "\n",
    "    # Negative interaction based on Protein\n",
    "    protein_clan = row['Sequence_2_clan']\n",
    "    non_interacting_families = filtered_families_per_protein_clan.get(protein_clan, [])\n",
    "    if non_interacting_families:\n",
    "        chosen_family = random.choice(non_interacting_families)\n",
    "        # Assuming you have a function to randomly select an RNA from a family\n",
    "        chosen_rna = randomly_select_rna_from_family(chosen_family, limit_rpi_df)\n",
    "        negative_entry = row.copy()\n",
    "        negative_entry.update(chosen_rna)  # Update the entry with the chosen RNA's information\n",
    "        negative_entry['interaction'] = False\n",
    "        negative_entry['RNAInterID'] = f\"N_{row['RNAInterID']}\"\n",
    "        negative_interactions.append(negative_entry)\n",
    "\n",
    "# Convert the list of negative interactions to a DataFrame\n",
    "negative_interactions_df = pd.DataFrame(negative_interactions)\n",
    "\n",
    "# Concatenate the original DataFrame with the negative interactions DataFrame\n",
    "all_interactions_df = pd.concat([limit_rpi_df, negative_interactions_df], ignore_index=True)\n",
    "all_interactions_df.to_parquet(os.path.join(INTER_DIR, 'all_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative interactions: 81,488\n",
      "Number of positive interactions: 40,744\n"
     ]
    }
   ],
   "source": [
    "# Quick analysis of the dataset\n",
    "print(f\"Number of negative interactions: {all_interactions_df[all_interactions_df['interaction'] == False].shape[0]:,}\")\n",
    "print(f\"Number of positive interactions: {all_interactions_df[all_interactions_df['interaction'] == True].shape[0]:,}\")\n",
    "\n",
    "assert all_interactions_df.shape[0] == limit_rpi_df.shape[0] + negative_interactions_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_protein_clans(all_interactions_df, fraction):\n",
    "    # Calculate the number of unique RNA families each protein clan interacts with\n",
    "    clan_variability = all_interactions_df.groupby('Sequence_2_clan')['Sequence_1_family'].nunique()\n",
    "\n",
    "    # Sort clans by variability (ascending)\n",
    "    sorted_clans = clan_variability.sort_values().index.tolist()\n",
    "\n",
    "    # Select the top fraction of clans\n",
    "    num_clans_to_select = int(len(sorted_clans) * fraction)\n",
    "    selected_clans = sorted_clans[:num_clans_to_select]\n",
    "    print(f\"Number of protein clans selected: {len(selected_clans)}\")\n",
    "    return selected_clans\n",
    "\n",
    "def create_train_test_sets(interactions_file, output_dir, test_set_clan_fraction=0.10):\n",
    "    # Read the dataframe\n",
    "    all_interactions_df = pd.read_parquet(interactions_file, engine='pyarrow')\n",
    "\n",
    "    # Select protein clans for test set\n",
    "    selected_clans = select_protein_clans(all_interactions_df, fraction=test_set_clan_fraction)\n",
    "\n",
    "    # Split the Data\n",
    "    test_df = all_interactions_df[all_interactions_df['Sequence_2_clan'].isin(selected_clans)]\n",
    "    train_df = all_interactions_df[~all_interactions_df['Sequence_2_clan'].isin(selected_clans)]\n",
    "\n",
    "    # Assertions to verify the splits\n",
    "    assert len(test_df) + len(train_df) == len(all_interactions_df)\n",
    "\n",
    "    # Count of unique RNA families in each set\n",
    "    unique_families_train = train_df['Sequence_1_family'].nunique()\n",
    "    unique_families_test = test_df['Sequence_1_family'].nunique()\n",
    "    \n",
    "    # Count of unique protein clans in each set\n",
    "    unique_clans_train = train_df['Sequence_2_clan'].nunique()\n",
    "    unique_clans_test = test_df['Sequence_2_clan'].nunique()\n",
    "    # assert unique_clans_train + unique_clans_test == len(unique_clans)\n",
    "\n",
    "    # Verify the splits\n",
    "    print(f\"Total data points: {len(all_interactions_df)}\")\n",
    "    print(f\"Training set size: {len(train_df)} -- {round(train_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "          -- {unique_families_train} unique RNA families \\\n",
    "          and {unique_clans_train} unique protein clans\")\n",
    "    print(f\"Test set size: {len(test_df)} -- {round(test_df.shape[0] / all_interactions_df.shape[0] * 100, 2)}% \\\n",
    "          -- {unique_families_test} unique RNA families \\\n",
    "          and {unique_clans_test} unique protein clans\")\n",
    "\n",
    "    # Save the Data\n",
    "    train_df.to_parquet(os.path.join(output_dir, 'train_set.parquet'), engine='pyarrow')\n",
    "    test_df.to_parquet(os.path.join(output_dir, 'test_set.parquet'), engine='pyarrow')\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of protein clans selected: 45\n",
      "Total data points: 122232\n",
      "Training set size: 109075 -- 89.24%           -- 1148 unique RNA families           and 107 unique protein clans\n",
      "Test set size: 13157 -- 10.76%           -- 999 unique RNA families           and 45 unique protein clans\n"
     ]
    }
   ],
   "source": [
    "all_interactions_path = os.path.join(INTER_DIR, 'all_interactions.parquet')\n",
    "\n",
    "# Create train and test sets\n",
    "train_df, test_df = create_train_test_sets(all_interactions_path, INTER_DIR, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative interactions in the train set: 68,973\n",
      "Number of positive interactions in the train set: 40,102\n",
      "\n",
      "Number of negative interactions in the test set: 12,515\n",
      "Number of positive interactions in the test set: 642\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_parquet(os.path.join(INTER_DIR, 'train_set.parquet'), engine='pyarrow')\n",
    "test_set = pd.read_parquet(os.path.join(INTER_DIR, 'test_set.parquet'), engine='pyarrow')\n",
    "\n",
    "# check how many positive and negative samples in each set\n",
    "print(f\"Number of negative interactions in the train set: {train_set[train_set['interaction'] == False].shape[0]:,}\")\n",
    "print(f\"Number of positive interactions in the train set: {train_set[train_set['interaction'] == True].shape[0]:,}\\n\")\n",
    "print(f\"Number of negative interactions in the test set: {test_set[test_set['interaction'] == False].shape[0]:,}\")\n",
    "print(f\"Number of positive interactions in the test set: {test_set[test_set['interaction'] == True].shape[0]:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
