{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import statements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scripts import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T22:12:00.981611Z",
     "start_time": "2023-06-03T22:12:00.683012Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_df = utils.load_rna_inter('miRBase')\n",
    "rna_inter_df.to_parquet('Download_data_RP_miRBase.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load miRBase from database file\n",
    "miRBase is stored in embl file format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "miRNA_df = pd.DataFrame([dict(\n",
    "    Sequence_1_ID=record.id,\n",
    "    Sequence_1=str(record.seq),\n",
    "    Raw_ID1=f\"miRBase:{record.id}\",\n",
    "    Sequence_1_len=len(str(record.seq))\n",
    ") for record in SeqIO.parse(\"miRNA.dat\", \"embl\")])\n",
    "rna_inter_df = pd.read_parquet('Download_data_RP_miRBase.parquet', engine='pyarrow')\n",
    "rna_inter_df = rna_inter_df.loc[:, ['Raw_ID1']].drop_duplicates()\n",
    "miRNA_df = miRNA_df.merge(rna_inter_df, how='inner', on='Raw_ID1')\n",
    "# miRNA_df = miRNA_df.dropna(subset=['Sequence_1'])\n",
    "miRNA_df = miRNA_df.reset_index()\n",
    "miRNA_df = utils.remove_illegal_nucleotides(miRNA_df, ['Y', 'R', 'W', 'N', 'S', 'K', 'M', 'B'])\n",
    "\n",
    "utils.check_sequences(miRNA_df)\n",
    "miRNA_df.to_parquet('miRNA.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T22:16:51.097846Z",
     "start_time": "2023-06-03T22:16:49.370088Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calc recovery rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gene IDs before extraction:\t11,040\n",
      "Unique Gene IDs after extraction:\t3,803\n",
      "Extraction rate:\t34.45%\n"
     ]
    }
   ],
   "source": [
    "miRNA_df = pd.read_parquet('miRNA.parquet', engine='pyarrow')\n",
    "rna_inter_df = pd.read_parquet('Download_data_RP_Ensembl.parquet', engine='pyarrow')\n",
    "utils.calc_recovery_rate(rna_inter_df, miRNA_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T22:16:52.995314Z",
     "start_time": "2023-06-03T22:16:52.689857Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load miRBase entries from RNAInter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_df = utils.load_rna_inter('miRBase')\n",
    "rna_inter_df.to_parquet('Download_data_RP_miRBase.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_df = pd.read_parquet('Download_data_RP_miRBase.parquet', engine='pyarrow')\n",
    "print(f\"RNAInter database loaded with size: {rna_inter_df.shape[0]:,}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df_1 = pd.merge(miRNA_df, rnainter_df, left_on='sequence_id', right_on='Raw_ID1')\n",
    "print(merged_df_1.shape[0])\n",
    "merged_df_2 = pd.merge(miRNA_df, rnainter_df, left_on='sequence_id', right_on='Raw_ID2')\n",
    "print(merged_df_2.shape[0])\n",
    "merged_df = pd.concat([merged_df_1, merged_df_2])\n",
    "print(merged_df.shape[0])\n",
    "merged_df.to_csv('merged_miRNABase.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('merged_miRNABase.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze sizes merged dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sizes = [100, 200, 216]\n",
    "for size in sizes:\n",
    "    df_size = merged_df[merged_df['sequence_len'] < size].shape[0]\n",
    "    print(f\"There are {df_size:,} interactions with a length < {size}\")\n",
    "print(f\"Max sequence length: {merged_df['sequence_len'].max()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df['strong_exists'] = ~merged_df['strong'].isnull()\n",
    "merged_df['weak_exists'] = ~merged_df['weak'].isnull()\n",
    "merged_df['predict_exists'] = ~merged_df['predict'].isnull()\n",
    "# df['Discount_rating'] = np.where(df['Discount'] > 2000, 'Good', 'Bad')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for quality in ['strong', 'weak', 'predict']:\n",
    "    df_size = merged_df[merged_df[f'{quality}_exists'] == True].shape[0]\n",
    "    print(f\"There are {df_size:,} interactions with a {quality} prediction\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ranges = np.arange(0.0, 1.1, 0.1)\n",
    "merged_df['score'] = merged_df['score'].astype(float)\n",
    "merged_df = merged_df[~pd.isnull(merged_df['score'])]\n",
    "for idx in range(1, len(ranges)):\n",
    "    df_size = merged_df[(merged_df['score'] >= ranges[idx -1 ]) & (merged_df['score'] < ranges[idx])].shape[0]\n",
    "    print(f\"There are {df_size:,} interactions between confidence score {round(ranges[idx - 1], 2)} and {round(ranges[idx], 2)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
