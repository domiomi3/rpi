{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# analze sequenes with range\n",
    "how many of them are a valid option??"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Module\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scripts import utils\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "from more_itertools import chunked\n",
    "from tqdm import tqdm\n",
    "Entrez.email = \"gernel@informatik.uni-freiburg.de\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T23:17:16.495858Z",
     "start_time": "2023-06-03T23:17:16.007883Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fetch regular sequences from genes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First load NCBI entries\n",
    "rna_inter_df = utils.load_rna_inter('NCBI')\n",
    "rna_inter_df.to_parquet('Download_data_RP_NCBI.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_df = pd.read_parquet('Download_data_RP_NCBI.parquet', engine='pyarrow')\n",
    "print(rna_inter_df.columns)\n",
    "\n",
    "print(f\"There are {rna_inter_df.shape[0]:,} interactions with RNAs from NCBI\")\n",
    "# obtain unique sequences\n",
    "ncbi_rna_ids = list(rna_inter_df['Raw_ID1'].unique())\n",
    "print(f\"There are {len(ncbi_rna_ids):,} unique gene IDs\")\n",
    "ncbi_rna_ids = [rna_id[5:] for rna_id in ncbi_rna_ids]\n",
    "# delete df to save memory :)\n",
    "del rna_inter_df\n",
    "file = open('ncbi_rna_ids.pickle', 'wb')\n",
    "pickle.dump(ncbi_rna_ids, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = open('ncbi_rna_ids.pickle', 'rb')\n",
    "ncbi_rna_ids = pickle.load(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_ncbi_nucleotide_ids(ids: list):\n",
    "    handle = Entrez.elink(db=\"nucleotide\", dbfrom=\"gene\", id=ids)\n",
    "    records = Entrez.read(handle)\n",
    "    temp_results = []\n",
    "    for record in records:\n",
    "        if record['IdList'] == ['0', '0']:\n",
    "            # This entry does not exist. Therefore, we skipped it.\n",
    "            continue\n",
    "        assert len(record['IdList']) == 1\n",
    "        gene_id = record['IdList'][0]\n",
    "        for link in record['LinkSetDb']:\n",
    "            if link['LinkName'] != 'gene_nuccore_refseqrna':\n",
    "                continue\n",
    "            temp_results += [dict(Raw_ID1=gene_id, Sequence_1_ID=seq['Id']) for seq in link['Link']]\n",
    "    return temp_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_ncbi_nucleotide_sequences(ids: list) -> list:\n",
    "    # Fetch the nucleotide sequences from NCBI\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=ids, rettype=\"gb\", retmode='xml')\n",
    "        # Read the nucleotide sequences into a list\n",
    "        records = Entrez.read(handle)\n",
    "        return [dict(\n",
    "            Sequence_1=record.get('GBSeq_sequence'),\n",
    "            Sequence_1_len=len(record.get('GBSeq_sequence')),\n",
    "            Sequence_1_ID=record.get('GBSeq_locus'),\n",
    "            Sequence_1_ID2=record.get('GBSeq_other-seqids')[1][3:]\n",
    "        ) for record in records]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncbi_results_df = utils.call_fetch_function(fetch_ncbi_nucleotide_ids, 100, ncbi_rna_ids)\n",
    "print(f\"{len(list(ncbi_results_df['Raw_ID1'].unique()))}/{len(ncbi_rna_ids)} unique gene_ids fetched\")\n",
    "ncbi_results_df.to_parquet('ncbi_results_1.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get missing chunk\n",
    "missing_rna_ids = list(chunked(ncbi_rna_ids, 1000))[57]\n",
    "missing_sequence_ids = pd.DataFrame(fetch_ncbi_nucleotide_ids(missing_rna_ids))\n",
    "print(f\"Fetched {len(list(missing_sequence_ids['Raw_ID1'].unique()))}/{len(missing_rna_ids)} of missing rna ids\")\n",
    "missing_sequence_ids.to_parquet('ncbi_results_2.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncbi_results_df = pd.concat((\n",
    "    pd.read_parquet('ncbi_results_1.parquet', engine='pyarrow'),\n",
    "    pd.read_parquet('ncbi_results_2.parquet', engine='pyarrow')\n",
    "    ))\n",
    "ncbi_results_df.to_parquet('ncbi_results.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncbi_results_df = pd.read_parquet('ncbi_results.parquet', engine='pyarrow')\n",
    "print(ncbi_results_df.shape[0])\n",
    "unique_sequence_ids = list(ncbi_results_df['Sequence_1_ID'].unique())\n",
    "print(len(unique_sequence_ids))\n",
    "file = open('unique_sequence_ids.pickle', 'wb')\n",
    "pickle.dump(unique_sequence_ids, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fetch sequence with obtained sequence IDs\n",
    "file = open('unique_sequence_ids.pickle', 'rb')\n",
    "unique_sequence_ids = pickle.load(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [{'Id': '332164660'}, {'Id': '332164659'}]\n",
    "unique_sequence_ids = unique_sequence_ids[:100]\n",
    "ncbi_rna_sequences_df = utils.call_fetch_function(fetch_ncbi_nucleotide_sequences, 10, unique_sequence_ids)\n",
    "# by default, compression is active :)\n",
    "ncbi_rna_sequences_df.to_parquet('ncbi_rna_sequences.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fetch missing sequences for missing sequence_ids\n",
    "unique_sequence_ids_2 = list(missing_sequence_ids['Sequence_1_ID'].unique())\n",
    "ncbi_rna_sequences_2_df = utils.call_fetch_function(fetch_ncbi_nucleotide_sequences, 100, unique_sequence_ids_2)\n",
    "ncbi_rna_sequences_2_df.to_parquet('ncbi_rna_sequences_2.parquet', engine='pyarrow')\n",
    "print(f\"{len(list(ncbi_rna_sequences_2_df['Sequence_1_ID'].unique()))}/{len(unique_sequence_ids_2)} from missing sequences fetched.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncbi_rna_sequences_df = pd.concat((pd.read_parquet('ncbi_rna_sequences_1.parquet', engine='pyarrow'),\n",
    "                                   pd.read_parquet('ncbi_rna_sequences_2.parquet', engine='pyarrow')))\n",
    "# ncbi_rna_sequences_df = ncbi_rna_sequences_df.drop(columns='Sequence_1_ID2')\n",
    "ncbi_rna_sequences_df.to_parquet('ncbi_rna_sequences.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# merge gene_ids and sequence ids\n",
    "ncbi_results_df = pd.read_parquet('ncbi_results.parquet', engine='pyarrow')\n",
    "ncbi_rna_sequences_df = pd.read_parquet('ncbi_rna_sequences.parquet', engine='pyarrow')\n",
    "ncbi_rna_sequences_df[['Sequence_1_ID', 'Sequence_1_ID2']] = ncbi_rna_sequences_df[['Sequence_1_ID2', 'Sequence_1_ID']]\n",
    "ncbi_rna_df = ncbi_results_df.merge(ncbi_rna_sequences_df, how='inner', on='Sequence_1_ID')\n",
    "del ncbi_results_df\n",
    "del ncbi_rna_sequences_df\n",
    "# ncbi_rna_df = ncbi_results_df.set_index('Sequence_1_ID').join(ncbi_rna_sequences_df.set_index('Sequence_1_ID'))\n",
    "ncbi_rna_df['Raw_ID1'] = \"NCBI:\" + ncbi_rna_df['Raw_ID1'].astype(str)\n",
    "ncbi_rna_df = ncbi_rna_df.drop(['Sequence_1_ID2'], axis=1)\n",
    "ncbi_rna_df['Sequence_1'] = ncbi_rna_df['Sequence_1'].str.upper()\n",
    "ncbi_rna_df['Sequence_1'] = ncbi_rna_df['Sequence_1'].str.replace('T', 'U')\n",
    "ncbi_rna_df = utils.remove_illegal_nucleotides(ncbi_rna_df, ['N', 'Y', 'B', 'M', 'S', 'K', 'R', 'W', 'D'])\n",
    "utils.check_sequences(ncbi_rna_df)\n",
    "ncbi_rna_df.to_parquet('ncbi_rna.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T23:24:55.882396Z",
     "start_time": "2023-06-03T23:23:33.276739Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calc recovery rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gene IDs before extraction:\t148,535\n",
      "Unique Gene IDs after extraction:\t131,277\n",
      "Extraction rate:\t88.38%\n"
     ]
    }
   ],
   "source": [
    "rna_inter_df = pd.read_parquet('Download_data_RP_NCBI.parquet', engine='pyarrow')\n",
    "ncbi_rna_df = pd.read_parquet('ncbi_rna.parquet', engine='pyarrow')\n",
    "utils.calc_recovery_rate(rna_inter_df, ncbi_rna_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T23:27:46.391759Z",
     "start_time": "2023-06-03T23:27:09.361097Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ncbi_rna_df: 494057\n",
      "Number of unique sequence_ids: 493411\n",
      "Number of unique sequences: 472378\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m test_df_2 \u001B[38;5;241m=\u001B[39m ncbi_rna_df\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRaw_ID1\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSequence_1_len\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstd()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# NCBI:100001267\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m test_df \u001B[38;5;241m=\u001B[39m \u001B[43mncbi_rna_df\u001B[49m[ncbi_rna_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRaw_ID1\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNCBI:100001267\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[11], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m test_df_2 \u001B[38;5;241m=\u001B[39m ncbi_rna_df\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRaw_ID1\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSequence_1_len\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstd()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# NCBI:100001267\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m test_df \u001B[38;5;241m=\u001B[39m \u001B[43mncbi_rna_df\u001B[49m[ncbi_rna_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRaw_ID1\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNCBI:100001267\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/231.9011.38/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:747\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 747\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/231.9011.38/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:144\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/231.9011.38/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/231.9011.38/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# analyse ncbi results dataframe\n",
    "ncbi_rna_df = pd.read_parquet('ncbi_rna.parquet', engine='pyarrow')\n",
    "print(f\"Size of ncbi_rna_df: {ncbi_rna_df.shape[0]}\")\n",
    "print(f\"Number of unique sequence_ids: {ncbi_rna_df['Sequence_1_ID2'].nunique()}\")\n",
    "print(f\"Number of unique sequences: {ncbi_rna_df['Sequence_1'].nunique()}\")\n",
    "\n",
    "test_df_2 = ncbi_rna_df.groupby(['Raw_ID1'])['Sequence_1_len'].std()\n",
    "# NCBI:100001267\n",
    "test_df = ncbi_rna_df[ncbi_rna_df['Raw_ID1'] == 'NCBI:100001267']\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sequences with ranges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load sequences with range\n",
    "file = open('sequence_ids/sequence_ids_with_range.pickle', 'rb')\n",
    "sequences_with_range = pickle.load(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# flatten list\n",
    "sequences_with_range = [(key,seq2) for key, seq1 in sequences_with_range.items() for seq2 in seq1]\n",
    "seq_df = [dict(\n",
    "    gene_id=seq[0],\n",
    "    seq_id=seq[1][0],\n",
    "    seq_start=int(seq[1][1]),\n",
    "    seq_end=int(seq[1][2]),\n",
    "    seq_len=int(seq[1][2]) - int(seq[1][1])\n",
    ") for seq in sequences_with_range]\n",
    "seq_df = pd.DataFrame(seq_df)\n",
    "seq_df.to_parquet('sequence_ids_with_range.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seq_df = pd.read_parquet('sequence_ids_with_range.parquet')\n",
    "seq_df['seq_id'] = seq_df['seq_id'].astype(str) + \":\" + seq_df['seq_start'].astype(str) + \"-\" + seq_df['seq_end'].astype(str)\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out long sequences\n",
    "seq_df = seq_df[seq_df['seq_len'] < 2000]\n",
    "# seq_df = seq_df.to_dict('records')\n",
    "# results = utils.fetch_ncbi_rna_fasta_with_range(seq_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this file containes RNA sequences which are shorter than 2000 bps.\n",
    "file = open('fetch_results.pickle', 'rb')\n",
    "raw_sequences = pickle.load(file)\n",
    "file.close()\n",
    "# flatten the list\n",
    "raw_sequences = [(seq[0], seq1) for seq in raw_sequences for seq1 in seq[1]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_seq_df = pd.DataFrame([dict(\n",
    "    sequence_id=seq[1].id.split('.')[0] + \":\" + seq[1].id.split('.')[1].split(':')[1],\n",
    "    sequence=str(seq[1].seq),\n",
    "    sequence_len=len(str(seq[1].seq)) - 1\n",
    ") for seq in raw_sequences])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
