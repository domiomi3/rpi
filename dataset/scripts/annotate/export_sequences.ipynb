{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting Unique Sequences\n",
    "Notebook helps to export all unique RNA and protein sequences\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Protein Sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-22T12:13:22.281591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries:\t\t287,226\n",
      "Number of unique sequences:\t166,473\n",
      "Number of entries after dropping duplicates based on Raw_ID2 & Sequence 2: 167,227\n"
     ]
    }
   ],
   "source": [
    "seq_databases = [\n",
    "    'NCBI/ncbi_proteins.parquet',\n",
    "    'UniProt/protein_uniprot.parquet',\n",
    "]\n",
    "all_df = pd.DataFrame()\n",
    "for db in seq_databases:\n",
    "    temp_df = pd.read_parquet(db, engine='pyarrow')\n",
    "    all_df = pd.concat([all_df, temp_df])\n",
    "    del temp_df\n",
    "print(f\"Number of entries:\\t\\t{all_df.shape[0]:,}\")\n",
    "print(f\"Number of unique sequences:\\t{all_df['Sequence_2'].nunique():,}\")\n",
    "all_df = all_df.dropna(subset=['Sequence_2'])\n",
    "all_df['Sequence_2_shuffle'] = False\n",
    "all_df = all_df.drop_duplicates(subset=['Raw_ID2', 'Sequence_2'])\n",
    "print(f\"Number of entries after dropping duplicates based on Raw_ID2 & Sequence 2: {all_df.shape[0]:,}\")\n",
    "all_df.to_parquet('protein_sequences.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T12:13:26.100091Z",
     "start_time": "2023-06-22T12:13:24.613842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "all_df = pd.read_parquet('protein_sequences.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T12:13:43.744429Z",
     "start_time": "2023-06-22T12:13:43.564868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133,069/167,227\n"
     ]
    }
   ],
   "source": [
    "# store rna sequences shorter than 1024\n",
    "all_df_short = all_df[all_df['Sequence_2_len'] <= 1024]\n",
    "print(f\"{all_df_short.shape[0]:,}/{all_df.shape[0]:,}\")\n",
    "\n",
    "all_df_short.to_parquet('protein_sequences_short.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T12:13:58.069519Z",
     "start_time": "2023-06-22T12:13:57.946176Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNA Sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seq_databases = [\n",
    "    'Ensembl/Ensembl.parquet',\n",
    "    'miRBase/miRNA.parquet',\n",
    "    'NCBI/ncbi_rna.parquet',\n",
    "    'NONCODE/NONCODE.parquet'\n",
    "]\n",
    "all_df = pd.DataFrame()\n",
    "for db in seq_databases:\n",
    "    temp_df = pd.read_parquet(db, engine='pyarrow')\n",
    "    all_df = pd.concat([all_df, temp_df])\n",
    "    del temp_df\n",
    "print(f\"Number of entries:\\t\\t{all_df.shape[0]:,}\")\n",
    "print(f\"Number of unique sequences:\\t{all_df['Sequence_1'].nunique():,}\")\n",
    "all_df = all_df.dropna(subset=['Sequence_1'])\n",
    "all_df = all_df.drop(['index'], axis=1)\n",
    "all_df['Sequence_1_shuffle'] = False\n",
    "all_df.to_parquet('rna_sequences.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_df = pd.read_parquet('rna_sequences.parquet', engine='pyarrow')\n",
    "# store rna sequences shorter than 150 bps\n",
    "all_df_short = all_df[all_df['Sequence_1_len'] <= 150]\n",
    "print(f\"{all_df_short.shape[0]:,}/{all_df.shape[0]:,}\")\n",
    "all_df_short.to_parquet('rna_sequences_short.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Store fasta file of all unique RNA sequences (specific for RNA-FM)\n",
    "all_df = all_df.sort_values(by=['Sequence_1_len'])\n",
    "all_df = all_df.dropna(subset=['Sequence_1'])\n",
    "print(f\"Number of sequences: {all_df.shape[0]}\")\n",
    "# Filter out sequences which are longer than 10000 BPs\n",
    "all_df = all_df[all_df['Sequence_1_len'] <= 1024]\n",
    "# rna_sequences = [SeqIO.SeqRecord(Seq(seq['Sequence_1']), id=seq['Raw_ID1'], description=\"\") for idx, seq in all_df.iterrows()]\n",
    "rna_sequences = [(seq['Raw_ID1'], seq['Sequence_1']) for _, seq in all_df.iterrows()]\n",
    "print(len(rna_sequences))\n",
    "with open('unique_rna_sequences.pickle', 'wb') as file:\n",
    "    pickle.dump(rna_sequences, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
