{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from random import choice\n",
    "import os\n",
    "\n",
    "\n",
    "src_dir = Path.cwd().parent\n",
    "sys.path.append(str(src_dir))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset Creation\n",
    "This dataset helps to create our final dataset with the given splits (Training Set, Test Set, Random Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = \"/work/dlclarge1/matusd-rpi/RPI/\" # change this to your working directory\n",
    "RESULTS_DIR = \"data/annotations/\"\n",
    "INTER_DIR = \"data/interactions/\"\n",
    "EMB_DIR = \"data/embeddings/\"\n",
    "RNAINTER_DIR = \"data/RNAInter/\"\n",
    "\n",
    "os.chdir(WORKING_DIR)\n",
    "\n",
    "if not os.path.exists(INTER_DIR):\n",
    "    os.makedirs(INTER_DIR)\n",
    "    \n",
    "if not os.path.exists(EMB_DIR):\n",
    "    os.makedirs(EMB_DIR)\n",
    "    \n",
    "# limit on number of interactions per protein/RNA\n",
    "PROTEIN_INTER = 150\n",
    "RNA_INTER = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RNAInter DB with interaction data\n",
    "\n",
    "# Create directory\n",
    "if not os.path.exists(RNAINTER_DIR):\n",
    "    os.makedirs(RNAINTER_DIR)\n",
    "\n",
    "rnainter_path = RNAINTER_DIR + \"Download_data_RP.txt\"\n",
    "\n",
    "# Download data\n",
    "if not os.path.exists(rnainter_path):\n",
    "    os.chdir(RNAINTER_DIR)\n",
    "\n",
    "    !wget http://www.rnainter.org/raidMedia/download/Download_data_RP.tar.gz\n",
    "    !tar -xf Download_data_RP.tar.gz\n",
    "    !rm Download_data_RP.tar.gz\n",
    "\n",
    "    os.chdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of RNA sequences: 7,847\n",
      "Number of protein sequences: 26,575\n"
     ]
    }
   ],
   "source": [
    "# Prepare RNA sequences DataFrame\n",
    "rna_sequences = pd.read_parquet(os.path.join(RESULTS_DIR, 'rna_short_families.parquet'), engine='pyarrow')\n",
    "\n",
    "# Drop entries lacking crucial information or duplicated\n",
    "rna_sequences = rna_sequences.dropna(subset=['Sequence_1', 'Raw_ID1', 'Sequence_1_family'])\n",
    "rna_sequences = rna_sequences.drop_duplicates(subset=['Raw_ID1'])\n",
    "\n",
    "print(f\"Number of RNA sequences: {rna_sequences.shape[0]:,}\")\n",
    "\n",
    "# Prepare protein sequences DataFrame\n",
    "protein_sequences = pd.read_parquet(os.path.join(RESULTS_DIR, 'proteins_short_clans.parquet'), engine='pyarrow')\n",
    "\n",
    "# Drop entries lacking crucial information or duplicated\n",
    "protein_sequences = protein_sequences.dropna(subset=['Sequence_2', 'Raw_ID2', 'Sequence_2_clan'])\n",
    "protein_sequences= protein_sequences.drop_duplicates(subset=['Raw_ID2'])\n",
    "\n",
    "print(f\"Number of protein sequences: {protein_sequences.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions in RNAInter: 37,067,587\n"
     ]
    }
   ],
   "source": [
    "# Load raw RNAInter database\n",
    "rna_inter_df = utils.load_rna_inter_csv(rnainter_path)\n",
    "print(f\"Number of interactions in RNAInter: {rna_inter_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (positive) interactions with annotated entries: 488,184 \n",
      "\n",
      "RPI dataframe columns: \n",
      " ['RNAInterID', 'Interactor1.Symbol', 'Category1', 'Species1', 'Interactor2.Symbol', 'Category2', 'Species2', 'Raw_ID1', 'Raw_ID2', 'score', 'strong', 'weak', 'predict', 'Sequence_1_rfam_q_accession', 'Sequence_1_family', 'Sequence_1_rfam_t_accession', 'Sequence_1_rfam_description', 'Sequence_1_rfam_e_value', 'Sequence_1', 'Sequence_1_len', 'Sequence_1_ID', 'Sequence_2_clan', 'Sequence_2_ID', 'Sequence_2', 'Sequence_2_len', 'interaction'] \n",
      "\n",
      "RPI sample entries: \n",
      "    RNAInterID Interactor1.Symbol Category1      Species1 Interactor2.Symbol Category2      Species2         Raw_ID1     Raw_ID2   score strong       weak                                    predict Sequence_1_rfam_q_accession Sequence_1_family Sequence_1_rfam_t_accession              Sequence_1_rfam_description  Sequence_1_rfam_e_value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Sequence_1  Sequence_1_len Sequence_1_ID Sequence_2_clan Sequence_2_ID                                                                                                                                                                                                                                     Sequence_2  Sequence_2_len  interaction\n",
      "0  RP34117562      2010103J01Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus      NCBI:69889  NCBI:56758  0.1229    NaN        NaN  Scan pipeline widely used MATCH algorithm                           -           mir-192                     RF00130           mir-192/215 microRNA precursor             1.100000e-16                                                                                                                                                                                                                                                    ACUCAGGACUUCCAGGUAAGGAGCCGCUGCUGUCCUCUUGGUCCUCUGUUCUCUCUUUAUAAGCAAAAGGCACAGGACAGGAUCUCUGCUGGAAGUGACCGUGGAAAGAACGAGUUCAAGUGCUAGGUCAGCAGAGGACCCAGCCAUGGAGACUACGGAGCACGGAGCUCUCAGCAUCAACGGUGUACAGGAGAAUGACCUAUGAUUUGACAGACCGUGCAGCUGUGUAUGUCUGUCAUUCUGUAGGCCAAUAUUCUGUAUGUCACUGCUACUUAAAAUCCGGACAUCGGCAAACACCCUCUGAGCGCUGUGCAGCAGAUCACGGGAGAGUCUGUAGCAUGGCAGGAGAAUGUGCUGACAAAAUAAAAUGAGUGCUUCUGUGUA             384    1907071096          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n",
      "1  RP34118868      2310002D06Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus      NCBI:69522  NCBI:56758  0.1229    NaN        NaN  Scan pipeline widely used MATCH algorithm                           -                U3                     RF00012                   Small nucleolar RNA U3             9.900000e-07                                                                                                                        AGAUUCUGCUUGCUGUAGCCAAUAAGCACAACAGCUUGGAAGCAAUGCUGCAGGCAGCCGGCACCCUCACUGUGCAGCUGAGAAAACUGAGGCUGAGAAUUGACCGGAGCCACCUCAUAGAUGGCUUCAUUCGCAAGCCUGACCUGUCUUGGAUUUUCCGAAGAGUCAACCUACCUGACAUCAUCCAAAAAGCACCACCCUGUCCACUCUGCUCCUGGCAUUUAAGAUCCUCCAGUAUCUAGACUUGCCCAGUCUGGCCAGUCUCAACUCACACCAGGUCUUUGCCAGUAUCCAGCAUGCUCUCAUGAGAUAUUAUCCUGAGGGCCUUGGCUGUCCCUGCCCUUUCCUUAUUCUUCUCUUCCUUUUUGGGAUUACCCUCCUAUUCUCCAGAUUUAUCCACUUUCUCUGGGAAGCCUUCCUAAAGACCACUUUGCAAGACUAUACUUUCAGGAAUCAUUUCUGUAGUUCGUUACUGAAGACCAGUUUGCAAUAAAUUAUUUCUUCCUCC             508     356460946          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n",
      "2  RP09023616      5430416N02Rik    lncRNA  Mus musculus              Mbnl1       RBP  Mus musculus  NCBI:100503199  NCBI:56758  0.1229    NaN  HITS-CLIP  Scan pipeline widely used MATCH algorithm                           -         adapt33_3                     RF02257  Adaptive response 33 conserved region 3             9.600000e-27  CCGUGGGCACGUUCUCGCUUCCAUUCGGUCCUCCUUUUGUUAACGCUCUGGCAUCAUGUCUACGCCAGCUCCCGCGCAAUCCGGCGCCAUCGCGCUUUGGGCGAGCAUGGCCAUGGGGAGUAGAGAGGUGGAAACCGAGCUGACGCCUGCCUGACCCUGGCGAUGGUGGCGCGCGCCGGGAAGGACUGAUUGGAGAAUGGCGCCAAAUGGGUCACGGAUGGCGAGGGGGCACAGGAGCUCUCGAUGUGACCUGGCGCUGUGGAUGUGAUGCACAGCAGCUUGAGUGGGACUGCUCCGCUGUCCUCAUGAGAGAACGCUUUUUCUGAAGAUGGGAGGUGGCUAAUGAAAGAAGGAAUUGUGUUCUCGGUGAUGCCUGGAAGAGAUGCGUGACGUUGGAAGAUGAUUACGAAAUACAGGAAAGGAAUGAAAUCAAAGGAUGUUUUUUGUAAGAGUAACACUUACAGAAAUAUUCAUUAAUUUGAAGAUUUAUAUAAGGCCUGGUGACCUCCGUUAAUUCCUGGGACCCACAGUGUGGAAGAAGAGACCUGACUCCUGAAAGUUGUCUUCUGACCACAUAUACACAAUAUGUAAAUAAAUGUAAUUAAAAAAUCAAAAUAGUAAAACUG             626     300360574          CL0537    1907151557  mamlaqqmqlanammpgaplqpvpmfsvapslatsasaafnpylgpvspslvpaeilptapmlvtgnpgvpvpaaaaaaaqklmrtdrlevcreyqrgncnrgendcrfahpadstmidtndntvtvcmdyikgrcsrekckyfhppahlqakikaaqyqvnqaaaaqaaataaamgipqavlpplpkrpalektngatavfntgifqyqqalanmqlqqhtaflppdthnicrtsd             237         True\n"
     ]
    }
   ],
   "source": [
    "# Merge RNAInter and sequences DataFrames\n",
    "rpi_df = rna_inter_df.merge(rna_sequences, on='Raw_ID1', how='inner').merge(protein_sequences, on='Raw_ID2', how='inner')\n",
    "\n",
    "# Create interaction label for classification\n",
    "rpi_df['interaction'] = True\n",
    "\n",
    "print(f\"Number of (positive) interactions with annotated entries: {rpi_df.shape[0]:,} \\n\")\n",
    "print(f\"RPI dataframe columns: \\n {rpi_df.columns.to_list()} \\n\")\n",
    "print(f\"RPI sample entries: \\n {rpi_df.head(3).to_string()}\")\n",
    "\n",
    "# Save RPI DataFrame\n",
    "rpi_df.to_parquet(os.path.join(INTER_DIR, 'raw_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 25010 mRNA interactions.\n",
      "Number of interactions after removing duplicates: 463,133\n",
      "Number of interactions after limiting number of interactions per protein/RNA: 40,891 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpi_df = pd.read_parquet(os.path.join(INTER_DIR, 'raw_interactions.parquet'), engine='pyarrow')\n",
    "\n",
    "# Remove mRNA interactors (ESM-2 model was trained only on non-coding RNAs)\n",
    "len_before = rpi_df.shape[0]\n",
    "rpi_df = rpi_df[rpi_df['Category1'].str.lower() != 'mrna']\n",
    "print(f\"Removed {len_before-rpi_df.shape[0]} mRNA interactions.\")\n",
    "\n",
    "# Remove interactions with more than one occurence and with duplicated both interactors\n",
    "rpi_df = rpi_df.drop_duplicates(subset=['RNAInterID'])\n",
    "rpi_df = rpi_df.drop_duplicates(subset=['Raw_ID1', 'Raw_ID2'])\n",
    "print(f\"Number of interactions after removing duplicates: {rpi_df.shape[0]:,}\")\n",
    "\n",
    "# Limit number of interactions per protein/RNA\n",
    "limit_rpi_df = rpi_df.groupby(by=['Raw_ID1']).filter(lambda x: len(x) < RNA_INTER)\n",
    "limit_rpi_df = limit_rpi_df.groupby(by=['Raw_ID2']).filter(lambda x: len(x) < PROTEIN_INTER)\n",
    "print(f\"Number of interactions after limiting number of interactions per protein/RNA: {limit_rpi_df.shape[0]:,} \\n\")\n",
    "limit_rpi_df.to_parquet(os.path.join(INTER_DIR, 'limited_interactions.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique RNA sequences: 4,177\n",
      "Number of RNA families: 1,148 \n",
      "\n",
      "Number of unique protein sequences: 1,325\n",
      "Number of protein clans: 152\n"
     ]
    }
   ],
   "source": [
    "# Quick data analysis\n",
    "print(f\"Number of unique RNA sequences: {limit_rpi_df['Sequence_1'].nunique():,}\")\n",
    "print(f\"Number of RNA families: {limit_rpi_df['Sequence_1_family'].nunique():,} \\n\")\n",
    "print(f\"Number of unique protein sequences: {limit_rpi_df['Sequence_2'].nunique():,}\")\n",
    "print(f\"Number of protein clans: {limit_rpi_df['Sequence_2_clan'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique RNA and protein sequences for the embedding stage\n",
    "unique_proteins = limit_rpi_df.drop_duplicates(subset=['Sequence_2_ID', 'Sequence_2'])\n",
    "unique_RNA = limit_rpi_df.drop_duplicates(subset=['Sequence_1_ID', 'Sequence_1'])\n",
    "\n",
    "unique_proteins.to_parquet(os.path.join(EMB_DIR, 'unique_proteins.parquet'), engine='pyarrow')\n",
    "unique_RNA.to_parquet(os.path.join(EMB_DIR, 'unique_RNA.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3: Negative interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive interactions: 13,330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 182/13330 [00:01<01:38, 133.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13330/13330 [01:25<00:00, 156.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative interactions based on RNA interactor: 13,330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13330/13330 [01:25<00:00, 156.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative interactions based on protein interactor: 13,330\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(INTER_DIR, 'limited_interactions.parquet'), engine='pyarrow')\n",
    "print(f\"Number of positive interactions: {df.shape[0]:,}\")\n",
    "\n",
    "# Create negative interactions for RNA interactors\n",
    "neg_rna_df = utils.create_negative_dataset_per_interactor(df, 1)\n",
    "print(f\"Number of negative interactions based on RNA interactor: {neg_rna_df.shape[0]:,}\")\n",
    "\n",
    "# Create negative interactions for protein interactors\n",
    "neg_protein_df = utils.create_negative_dataset_per_interactor(df, 2)\n",
    "print(f\"Number of negative interactions based on protein interactor: {neg_protein_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all interactions: 39,990\n"
     ]
    }
   ],
   "source": [
    "# Merge negative interactions and save to parquet\n",
    "all_interactions_df = pd.concat([df, neg_rna_df, neg_protein_df])\n",
    "all_interactions_df.to_parquet(os.path.join(INTER_DIR, 'all_interactions.parquet'), engine='pyarrow')\n",
    "print(f\"Number of all interactions: {all_interactions_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 39990\n",
      "Training set size: 35992 -- 90.0 % -- 862 unique RNA families\n",
      "Test set size: 3998 -- 10.0 % -- 50 unique RNA families\n"
     ]
    }
   ],
   "source": [
    "all_interactions_df = pd.read_parquet(os.path.join(INTER_DIR, 'all_interactions.parquet'), engine='pyarrow')\n",
    "\n",
    "unique_families = all_interactions_df['Sequence_1_family'].unique()\n",
    "test_set_size = int(len(all_interactions_df) * 0.10)\n",
    "\n",
    "# Select RNA families for test set\n",
    "selected_families = []\n",
    "accumulated_size = 0\n",
    "for family in unique_families:\n",
    "    family_size = len(all_interactions_df[all_interactions_df['Sequence_1_family'] == family])\n",
    "    if accumulated_size + family_size <= test_set_size:\n",
    "        selected_families.append(family)\n",
    "        accumulated_size += family_size\n",
    "    if accumulated_size >= test_set_size:\n",
    "        break\n",
    "\n",
    "# Split the Data\n",
    "test_df = all_interactions_df[all_interactions_df['Sequence_1_family'].isin(selected_families)]\n",
    "train_df = all_interactions_df[~all_interactions_df['Sequence_1_family'].isin(selected_families)]\n",
    "assert len(test_df) + len(train_df) == len(all_interactions_df)\n",
    "\n",
    "# Count of unique RNA families in each set\n",
    "unique_families_train = train_df['Sequence_1_family'].nunique()\n",
    "unique_families_test = test_df['Sequence_1_family'].nunique()\n",
    "assert unique_families_train + unique_families_test == len(unique_families)\n",
    "\n",
    "# Verify the splits\n",
    "print(f\"Total data points: {len(all_interactions_df)}\")\n",
    "print(f\"Training set size: {len(train_df)} -- {round(train_df.shape[0] / all_interactions_df.shape[0] * 100, 2)} % -- {unique_families_train} unique RNA families\")\n",
    "print(f\"Test set size: {len(test_df)} -- {round(test_df.shape[0] / all_interactions_df.shape[0] * 100, 2)} % -- {unique_families_test} unique RNA families\")\n",
    "\n",
    "# Save the Data\n",
    "train_df.to_parquet(os.path.join(INTER_DIR, 'train_set.parquet'), engine='pyarrow')\n",
    "test_df.to_parquet(os.path.join(INTER_DIR, 'test_set.parquet'), engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
