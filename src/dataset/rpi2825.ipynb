{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RPI2825 dataset preparation\n",
    "This notebook helps to create the independent dataset RPI2825 for dataset creation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d41909029f9b7e2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rpi_db = pd.read_csv('RPI2825.csv')\n",
    "print(f\"Original RPI2825 has {len(rpi_db)} entries/interactions\")\n",
    "print(f\"Original RPI2825 has {len(list(rpi_db['protein_seq'].unique()))} unique protein sequences\")\n",
    "print(f\"Original RPI2825 has {len(list(rpi_db['rna_seq'].unique()))} unique RNA sequences\")\n",
    "# filter protein sequences longer 1024\n",
    "rpi_db['protein_seq_len'] = rpi_db['protein_seq'].apply(len)\n",
    "rpi_db = rpi_db[rpi_db['protein_seq_len'] <= 1024]\n",
    "# filter rna sequences longer 150\n",
    "rpi_db['rna_seq_len'] = rpi_db['rna_seq'].apply(len)\n",
    "rpi_db = rpi_db[rpi_db['rna_seq_len'] <= 150]\n",
    "print(f\"Filtered RPI2825 has {len(rpi_db)} entries/interactions\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "358135ad98a34cd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Filtered RPI2825 has {len(list(rpi_db['protein_seq'].unique()))} unique protein sequences\")\n",
    "print(f\"Filtered RPI2825 has {len(list(rpi_db['rna_seq'].unique()))} unique RNA sequences\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324afd900bc60e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rpi_db.to_parquet('rpi2825.parquet')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6007ee2fcf13c60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_train = pd.read_parquet('../results/dataset_v4/final_train_set_reduced.parquet')\n",
    "rna_inter_test = pd.read_parquet('../results/dataset_v4/final_test_set_reduced.parquet')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "200812dfbdd05b14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if there are unique sequences which are the same in both datasets\n",
    "rna_seqs_rpi_2825 = set(rpi_db['rna_seq'])\n",
    "rna_seqs_rna_inter_train = set(rna_inter_train['Sequence_1'])\n",
    "print(len(rna_seqs_rna_inter_train))\n",
    "rna_seqs_rna_inter_train = set([x.upper() for x in rna_seqs_rna_inter_train])\n",
    "rna_seqs_rna_inter_test = set(rna_inter_test['Sequence_1'])\n",
    "print(len(rna_seqs_rna_inter_test))\n",
    "rna_seqs_rna_inter_test = set([x.upper() for x in rna_seqs_rna_inter_test])\n",
    "print(f\"{len(rna_seqs_rpi_2825.intersection(rna_seqs_rna_inter_train))}\")\n",
    "print(f\"{len(rna_seqs_rpi_2825.intersection(rna_seqs_rna_inter_test))}\")\n",
    "print(f\"{len(rna_seqs_rna_inter_train.intersection(rna_seqs_rna_inter_test))}\")\n",
    "\n",
    "# Check if there are unique sequences which are the same in both datasets\n",
    "protein_seqs_rpi_2825 = set(rpi_db['protein_seq'])\n",
    "protein_seqs_rna_inter_train = set(rna_inter_train['Sequence_2'])\n",
    "protein_seqs_rna_inter_train = set([x.upper() for x in protein_seqs_rna_inter_train])\n",
    "protein_seqs_rna_inter_test = set(rna_inter_test['Sequence_2'])\n",
    "protein_seqs_rna_inter_test = set([x.upper() for x in protein_seqs_rna_inter_test])\n",
    "print(f\"{len(protein_seqs_rpi_2825.intersection(protein_seqs_rna_inter_train))}\")\n",
    "print(f\"{len(protein_seqs_rpi_2825.intersection(protein_seqs_rna_inter_test))}\")\n",
    "print(f\"{len(protein_seqs_rna_inter_train.intersection(protein_seqs_rna_inter_test))}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f6e9bbc6180520"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Store unique rna sequences to obtain rna family information\n",
    "unique_rna_df = rpi_db[['rna_seq']].drop_duplicates(subset=['rna_seq']).rename(columns={\n",
    "    'rna_seq': 'Sequence_1'\n",
    "})\n",
    "unique_rna_df['Sequence_1_ID'] = unique_rna_df.reset_index().index\n",
    "unique_rna_df['Raw_ID1'] = unique_rna_df['Sequence_1_ID']\n",
    "unique_rna_df.to_parquet(\"../results/rpi2825/rna_sequences.parquet\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fea9bd1f3778fb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load annotated data\n",
    "rna_families_df = pd.read_parquet('../results/rpi2825/rna_sequences_families.parquet')\n",
    "org_len = len(rpi_db)\n",
    "rna_families_df = rna_families_df.drop(columns=['Id'])\n",
    "rpi_db = rpi_db.rename(columns={\n",
    "    'rna_seq': 'Sequence_1'\n",
    "})\n",
    "rpi_db = rpi_db.merge(rna_families_df, on=['Sequence_1'])\n",
    "assert org_len == len(rpi_db)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "335445108dd87652"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_cluster_df = pd.read_parquet('../results/rpi2825/rna_sequences_clusters.parquet')\n",
    "org_len = len(rpi_db)\n",
    "rna_cluster_df = rna_cluster_df.drop(columns=['Sequence_1_ID', 'Raw_ID1'])\n",
    "rpi_db = rpi_db.merge(rna_cluster_df, on=['Sequence_1'])\n",
    "assert org_len == len(rpi_db)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc4a68fcae0eb478"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Store unique rna sequences to obtain rna family information\n",
    "unique_protein_df = rpi_db[['protein_seq']].drop_duplicates(subset=['protein_seq']).rename(columns={\n",
    "    'protein_seq': 'Sequence_2'\n",
    "})\n",
    "unique_protein_df['Sequence_2_ID'] = unique_protein_df.reset_index().index\n",
    "unique_protein_df['Raw_ID2'] = unique_protein_df['Sequence_2_ID']\n",
    "unique_protein_df.to_parquet(\"../results/rpi2825/protein_sequences.parquet\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8063d2ed0493b95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "protein_cluster_df = pd.read_parquet('../results/rpi2825/protein_sequences_clusters.parquet')\n",
    "org_len = len(rpi_db)\n",
    "protein_cluster_df = protein_cluster_df.drop(columns=['Sequence_2_ID', 'Raw_ID2'])\n",
    "rpi_db = rpi_db.rename(columns={\n",
    "    'protein_seq': 'Sequence_2'\n",
    "})\n",
    "rpi_db = rpi_db.merge(protein_cluster_df, on=['Sequence_2'])\n",
    "assert org_len == len(rpi_db)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9000d018c279e85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare extension\n",
    "rpi_db = rpi_db.assign(RNAInterID=range(len(rpi_db)))\n",
    "org_len = len(rpi_db)\n",
    "rpi_db = rpi_db.merge(unique_protein_df, on=['Sequence_2'])\n",
    "assert org_len == len(rpi_db)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acba3eb81feb51d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This function SELECTS for each interaction a new RNA-interaction partner from the entire dataset for a given protein-interaction partner\n",
    "def increase_set_1(limited_interactions: pd.DataFrame, dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Increase test-set for each protein-interaction\n",
    "    increased_set = pd.DataFrame()\n",
    "    for _, row in tqdm(dataset.iterrows(), total=dataset.shape[0]):\n",
    "        Raw_ID2 = row['Raw_ID2']\n",
    "        rna_family = row['Sequence_1_family']\n",
    "        rna_cluster = row['Sequence_1_cluster']\n",
    "        # rna_category = row['Category1']\n",
    "        # filter out every RNA that interacts with the same protein (Raw_ID2)\n",
    "        temp_df = limited_interactions[limited_interactions['Raw_ID2'] != Raw_ID2]\n",
    "        # Filter out same rna family of interactor\n",
    "        temp_df = temp_df[temp_df['Sequence_1_family'] != rna_family]\n",
    "        # Filter out same rna cluster of interactor\n",
    "        temp_df = temp_df[temp_df['Sequence_1_cluster'] != rna_cluster]\n",
    "        # Filter out same rna type of interactor\n",
    "        # temp_df = temp_df[temp_df['Category1'] != rna_category]\n",
    "        assert temp_df.shape[0] != 0\n",
    "        while True:\n",
    "            random_row = temp_df.sample().to_dict('records')[0]\n",
    "            if dataset[\n",
    "                (dataset['Raw_ID2'] == row['Raw_ID2']) &\n",
    "                (dataset['Sequence_2_ID'] == row['Sequence_2_ID']) &\n",
    "                (dataset['Raw_ID1'] == random_row['Raw_ID1']) &\n",
    "                (dataset['Sequence_1_ID'] == random_row['Sequence_1_ID'])\n",
    "            ].shape[0] == 0:\n",
    "                break\n",
    "            # print(\"Oups, some duplicate found\")\n",
    "\n",
    "        # merge random row and row\n",
    "        # Remove RNA elements from row\n",
    "        row = row.to_dict()\n",
    "        for k in ('Raw_ID1', 'Interactor1.Symbol', 'Category1', 'Species1', 'Sequence_1', 'Sequence_1_len',\n",
    "           'Sequence_1_ID', 'Sequence_1_shuffle', 'Sequence_1_cluster',\n",
    "           'Sequence_1_cluster_sim', 'Sequence_1_cluster_reference',\n",
    "           'Sequence_1_rfam_q_accession', 'Sequence_1_family',\n",
    "           'Sequence_1_rfam_t_accession', 'Sequence_1_rfam_description',\n",
    "           'Sequence_1_rfam_e_value', 'Id'):\n",
    "            row.pop(k, None)\n",
    "        # Remove protein elements from new rom\n",
    "        for k in ('Raw_ID2','Interactor2.Symbol', 'Category2', 'Species2', 'Sequence_2_ID', 'Sequence_2',\n",
    "           'Sequence_2_len', 'Sequence_2_shuffle', 'Sequence_2_cluster', 'Sequence_2_cluster_sim', 'Sequence_2_cluster_reference',\n",
    "            'score', 'strong', 'weak', 'predict', 'RNAInterID', 'Id'):\n",
    "            random_row.pop(k, None)\n",
    "        new_row = {**row, **random_row, 'score': 0, 'Sequence_1_shuffle': True, 'strong': float(\"nan\"),\n",
    "                   'weak': float(\"nan\"), 'predict': float(\"nan\")}\n",
    "        new_row['RNAInterID'] = str(new_row['RNAInterID']) + '.RV1'\n",
    "        increased_set = pd.concat([increased_set, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    assert dataset.shape[0] == increased_set.shape[0]\n",
    "    assert dataset.merge(increased_set, on=['Raw_ID1', 'Sequence_1_ID', 'Raw_ID2', 'Sequence_2_ID'], how='inner').shape[0] == 0\n",
    "    return increased_set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4224d0dc83d0b07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This function SELECTS for each interaction a new protein-interaction partner from the entire dataset for a given rna-interaction partner\n",
    "def increase_set_2(limited_interactions: pd.DataFrame, dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Increase test-set for each rna-interaction\n",
    "    increased_set = pd.DataFrame()\n",
    "    for _, row in tqdm(dataset.iterrows(), total=dataset.shape[0]):\n",
    "        Raw_ID1 = row['Raw_ID1']\n",
    "        protein_cluster = row['Sequence_2_cluster']\n",
    "        # protein_category = row['Category2']\n",
    "        # filter out every RNA that interacts with the same protein (Raw_ID2)\n",
    "        temp_df = limited_interactions[limited_interactions['Raw_ID1'] != Raw_ID1]\n",
    "        # Filter out same rna family of interactor\n",
    "        # Filter out same rna cluster of interactor\n",
    "        temp_df = temp_df[temp_df['Sequence_2_cluster'] != protein_cluster]\n",
    "        # Filter out same rna type of interactor\n",
    "        # temp_df = temp_df[temp_df['Category2'] != protein_cluster]\n",
    "        assert temp_df.shape[0] != 0\n",
    "        while True:\n",
    "            random_row = temp_df.sample().to_dict('records')[0]\n",
    "            if dataset[\n",
    "                (dataset['Raw_ID1'] == row['Raw_ID1']) &\n",
    "                (dataset['Sequence_1_ID'] == row['Sequence_1_ID']) &\n",
    "                (dataset['Raw_ID2'] == random_row['Raw_ID2']) &\n",
    "                (dataset['Sequence_2_ID'] == random_row['Sequence_2_ID'])\n",
    "            ].shape[0] == 0:\n",
    "                break\n",
    "            # print(\"Oups, some duplicate found\")\n",
    "\n",
    "        # merge random row and row\n",
    "        # Remove protein elements from row\n",
    "        row = row.to_dict()\n",
    "        for k in ('Raw_ID2', 'Interactor2.Symbol', 'Category2', 'Species2', 'Sequence_2', 'Sequence_2_len',\n",
    "           'Sequence_2_ID', 'Sequence_2_shuffle', 'Sequence_2_cluster',\n",
    "           'Sequence_2_cluster_sim', 'Sequence_2_cluster_reference',\n",
    "            'Id'):\n",
    "            row.pop(k, None)\n",
    "        # Remove rna elements from new rom\n",
    "        for k in ('Raw_ID1', 'Interactor1.Symbol', 'Category1', 'Species1', 'Sequence_1', 'Sequence_1_len',\n",
    "           'Sequence_1_ID', 'Sequence_1_shuffle', 'Sequence_1_cluster',\n",
    "           'Sequence_1_cluster_sim', 'Sequence_1_cluster_reference',\n",
    "           'Sequence_1_rfam_q_accession', 'Sequence_1_family',\n",
    "           'Sequence_1_rfam_t_accession', 'Sequence_1_rfam_description',\n",
    "           'Sequence_1_rfam_e_value',\n",
    "            'score', 'strong', 'weak', 'predict', 'RNAInterID', 'Id'):\n",
    "            random_row.pop(k, None)\n",
    "        new_row = {**row, **random_row}\n",
    "        new_row['score'] = 0\n",
    "        new_row['Sequence_2_shuffle'] = True\n",
    "        new_row['strong'] = float(\"nan\")\n",
    "        new_row['weak'] = float(\"nan\")\n",
    "        new_row['predict'] = float(\"nan\")\n",
    "        new_row['RNAInterID'] = str(new_row['RNAInterID']) + '.PV1'\n",
    "        increased_set = pd.concat([increased_set, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    assert dataset.shape[0] == increased_set.shape[0]\n",
    "    assert dataset.merge(increased_set, on=['Raw_ID1', 'Sequence_1_ID', 'Raw_ID2', 'Sequence_2_ID'], how='inner').shape[0] == 0\n",
    "    return increased_set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24f741a172077308"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_df_1 = increase_set_1(rpi_db, rpi_db)\n",
    "temp_df_2 = increase_set_2(rpi_db, rpi_db)\n",
    "rpi_db_extent = pd.concat([rpi_db, temp_df_1, temp_df_2])\n",
    "# assign unique Sequence IDs for embedding creation\n",
    "\n",
    "rpi_db['Sequence_1_ID_Unique'] = rpi_db.groupby(['Sequence_1']).ngroup()\n",
    "rpi_db['Sequence_2_ID_Unique'] = rpi_db.groupby(['Sequence_2']).ngroup()\n",
    "unique_proteins = rpi_db[['Sequence_2_ID_Unique', 'Sequence_2']].drop_duplicates()\n",
    "unique_RNAs = rpi_db[['Sequence_1_ID_Unique', 'Sequence_1']].drop_duplicates()\n",
    "unique_proteins.to_parquet(\"../results/rpi2825/unique_proteins.parquet\")\n",
    "unique_RNAs.to_parquet(\"../results/rpi2825/unique_RNAs.parquet\")\n",
    "assert len(rpi_db_extent) == len(rpi_db) * 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac7577f482f28039"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rpi_db_extent['RNAInterID'] = rpi_db_extent['RNAInterID'].astype(str)\n",
    "rpi_db_extent = rpi_db_extent.merge(unique_proteins, on=['Sequence_2'])\n",
    "rpi_db_extent = rpi_db_extent.merge(unique_RNAs, on=['Sequence_1'])\n",
    "rpi_db_extent.to_parquet(\"../results/rpi2825/rpi2825_extented.parquet\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcf4c2cbdf6dab0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
