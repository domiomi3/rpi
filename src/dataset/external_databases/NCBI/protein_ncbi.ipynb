{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import statements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from scripts import utils\n",
    "from Bio import Entrez\n",
    "from more_itertools import chunked\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "Entrez.email = \"gernel@informatik.uni-freiburg.de\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T12:30:48.395822Z",
     "start_time": "2023-07-10T12:30:46.601237Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load NCBI (protein) entries from RNAInter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "utils.show_rna_inter_protein_databases()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_df = utils.load_rna_inter_protein('NCBI')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rna_inter_df.to_parquet('rna_inter_protein.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of 39,009\n"
     ]
    }
   ],
   "source": [
    "rna_inter_df = pd.read_parquet('results/rna_inter_protein.parquet', engine='pyarrow')\n",
    "print(f\"size of {rna_inter_df.shape[0]:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T12:35:30.014596Z",
     "start_time": "2023-07-10T12:35:29.838867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del rna_inter_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obtaining unique protein IDs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gene_ids = pd.DataFrame(rna_inter_df['Raw_ID2'].unique(), columns=['Raw_ID2'])\n",
    "gene_ids.to_parquet('rna_inter_protein.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gene_ids = pd.read_parquet('rna_inter_protein.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gene_ids = list(gene_ids['Raw_ID2'])\n",
    "gene_ids = [gene_id[5:] for gene_id in gene_ids]\n",
    "print(f\"Number of unique proteins: {len(gene_ids)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_ncbi_nuccore_refseqrna_ids(ids: list):\n",
    "    handle = Entrez.elink(dbfrom=\"gene\", id=ids, linkname='gene_protein_refseq')\n",
    "    records = Entrez.read(handle)\n",
    "    temp_results = []\n",
    "    for record in records:\n",
    "        if record['IdList'] == ['0', '0']:\n",
    "            # This entry does not exist. Therefore, we skipped it.\n",
    "            continue\n",
    "        assert len(record['IdList']) == 1\n",
    "        gene_id = record['IdList'][0]\n",
    "        for link in record['LinkSetDb']:\n",
    "            if link['LinkName'] != 'gene_protein_refseq':\n",
    "                continue\n",
    "            temp_results += [dict(Raw_ID2=gene_id, Sequence_2_ID=seq['Id']) for seq in link['Link']]\n",
    "    return temp_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_ncbi_protein_sequences(ids: list):\n",
    "    handle = Entrez.efetch(db=\"protein\", id=ids, rettype=\"gb\", retmode='xml')\n",
    "    # Read the protein sequences into a list\n",
    "    records = Entrez.read(handle)\n",
    "    return [dict(\n",
    "            Sequence_2=record.get('GBSeq_sequence'),\n",
    "            Sequence_2_len=len(record.get('GBSeq_sequence')),\n",
    "            # Sequence_1_ID=record.get('GBSeq_locus'),\n",
    "            Sequence_2_ID=record.get('GBSeq_other-seqids')[1][3:]\n",
    "        ) for record in records]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 0\n",
    "count_2 = 0\n",
    "for gene_id in gene_ids:\n",
    "    gene_id = gene_id[5:]\n",
    "    protein_ids = fetch_ncbi_nuccore_refseqrna_ids(gene_id)\n",
    "    print(\" \".join([refseq['Sequence_1_ID_2'] for refseq in protein_ids]))\n",
    "    print(len(protein_ids))\n",
    "    for protein_id in protein_ids:\n",
    "        count_2 += 1\n",
    "        protein_id = protein_id['Sequence_1_ID_2']\n",
    "        uniprot_ids = utils.fetch_ncbi_uniprot_ids(protein_id)\n",
    "        if len(uniprot_ids) != 0:\n",
    "            count += 1\n",
    "            print(f\"{count}/{count_2}\")\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "protein_ids_df = utils.call_fetch_function(fetch_ncbi_nuccore_refseqrna_ids, 250, gene_ids)\n",
    "protein_ids_df.to_parquet('ncbi_proteins_ids.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# protein_ids_df.to_parquet('ncbi_proteins_ids.parquet', engine='pyarrow')\n",
    "protein_ids_df = pd.read_parquet('ncbi_proteins_ids.parquet', engine='pyarrow')\n",
    "protein_ids = list(protein_ids_df['Sequence_2_ID'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Get protein sequences\n",
    "protein_sequences = utils.call_fetch_function(fetch_ncbi_protein_sequences, 1000, protein_ids)\n",
    "protein_sequences.to_parquet('ncbi_protein_sequences.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "protein_sequences = pd.read_parquet('ncbi_protein_sequences.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Join sequences with corresponding ids\n",
    "ncbi_protein_df = protein_ids_df.merge(protein_sequences, on='Sequence_2_ID', how='inner')\n",
    "ncbi_protein_df['Raw_ID2'] = \"NCBI:\" + ncbi_protein_df['Raw_ID2'].astype(str)\n",
    "ncbi_protein_df.to_parquet('ncbi_proteins.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ncbi_protein_df = pd.read_parquet('results/ncbi_proteins.parquet', engine='pyarrow')\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T12:35:40.476984Z",
     "start_time": "2023-07-10T12:35:40.134742Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calc recovery rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gene IDs before extraction:\t39,009\n",
      "Unique Gene IDs after extraction:\t38,476\n",
      "Extraction rate:\t98.63%\n"
     ]
    }
   ],
   "source": [
    "utils.calc_recovery_rate(rna_inter_df, ncbi_protein_df, col_name='Raw_ID2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T12:35:41.896451Z",
     "start_time": "2023-07-10T12:35:41.858160Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obsolete Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_ids(ids):\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            handle = Entrez.efetch(db='gene', id=ids, retmode=\"xml\")\n",
    "            return Entrez.read(handle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    print(\"Something went 3 times wrong :(!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniport_ids = list()\n",
    "split_ids = list(chunked(protein_ids, 500))\n",
    "# handle = Entrez.elink(dbfrom='gene', id=protein_id, db='refseq')\n",
    "error_ids = []\n",
    "for ids in tqdm(split_ids):\n",
    "    records = get_ids(ids)\n",
    "    if records is None:\n",
    "        error_ids.append(ids)\n",
    "        continue\n",
    "    for record in records:\n",
    "        comments = record.get('Entrezgene_comments')\n",
    "        gene_id = record.get('Entrezgene_track-info').get('Gene-track').get('Gene-track_geneid')\n",
    "        for comment in comments:\n",
    "            if comment.get('Gene-commentary_heading') != 'NCBI Reference Sequences (RefSeq)':\n",
    "                continue\n",
    "            if comment.get('Gene-commentary_comment') is None:\n",
    "                continue\n",
    "            for commenary_commment in comment.get('Gene-commentary_comment'):\n",
    "                if commenary_commment.get('Gene-commentary_products') is None:\n",
    "                    continue\n",
    "                for product in commenary_commment.get('Gene-commentary_products'):\n",
    "                    if product.get('Gene-commentary_products') is None:\n",
    "                        continue\n",
    "                    for product_2 in product.get('Gene-commentary_products'):\n",
    "                        if product_2.get('Gene-commentary_comment') is None:\n",
    "                            continue\n",
    "                        for comment_2 in product_2.get('Gene-commentary_comment'):\n",
    "                            if comment_2.get('Gene-commentary_heading') != 'UniProtKB':\n",
    "                                continue\n",
    "                            for comment_3 in comment_2.get('Gene-commentary_comment'):\n",
    "                                if comment_3.get('Gene-commentary_source') is None:\n",
    "                                    continue\n",
    "                                for product_3 in comment_3.get('Gene-commentary_source'):\n",
    "                                    db = product_3.get('Other-source_src').get('Dbtag').get('Dbtag_db')\n",
    "                                    object_id = product_3.get('Other-source_src').get('Dbtag').get('Dbtag_tag').get('Object-id').get('Object-id_str')\n",
    "                                    uniport_ids.append(dict(\n",
    "                                        gene_id=gene_id,\n",
    "                                        db_type=db,\n",
    "                                        object_id=object_id\n",
    "                                    ))\n",
    "uniport_ids_df = pd.DataFrame(uniport_ids)\n",
    "uniport_ids_df.to_parquet('uniport_protein_ids.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniport_ids_df = pd.read_parquet('uniport_protein_ids.parquet', engine='pyarrow')\n",
    "uniport_ids_df = uniport_ids_df.drop_duplicates(subset=None, keep=\"first\", inplace=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "object_ids = list(uniport_ids_df['object_id'].unique())\n",
    "proteins = utils.fetch_protein_fasta(object_ids)\n",
    "\n",
    "file = open('proteins.pickle', 'wb')\n",
    "pickle.dump(proteins, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = open('proteins.pickle', 'rb')\n",
    "proteins = pickle.load(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert fasta string to Seq Objects\n",
    "proteins = [(protein[0], list(SeqIO.parse(io.StringIO(protein[1]), \"fasta\"))) for protein in proteins]\n",
    "# flatten list\n",
    "proteins = [(protein[0], seq) for protein in proteins for seq in protein[1]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniprot_proteins_df = [dict(\n",
    "    object_id=f\"{protein[0]}\",\n",
    "    protein_sequence=str(protein[1].seq),\n",
    "    protein_sequence_len=len(str(protein[1].seq)),\n",
    "    protein_id=protein[1].id,\n",
    "    protein_description=protein[1].description\n",
    ") for protein in proteins]\n",
    "uniprot_proteins_df = pd.DataFrame(uniprot_proteins_df)\n",
    "uniprot_proteins_df = pd.merge(uniprot_proteins_df, uniport_ids_df, left_on='object_id', right_on='object_id')\n",
    "uniprot_proteins_df['gene_id'] = \"NCBI:\" + uniprot_proteins_df['gene_id'].astype(str)\n",
    "uniprot_proteins_df = uniprot_proteins_df.drop(columns=['db_type', 'object_id'])\n",
    "uniprot_proteins_df.to_parquet(\"protein_ncbi.parquet\", engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load UniProt IDs which are stored directly in RNAInter database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniport_ids_2_df = utils.load_rna_inter_protein('UniProt')\n",
    "uniport_ids_2_df.to_parquet('RNAInter_uniport.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniport_ids_2_df = pd.read_parquet('RNAInter_uniport.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "object_ids = list(uniport_ids_2_df['Protein_ID'].unique())\n",
    "proteins = utils.fetch_protein_fasta(object_ids)\n",
    "# convert fasta string to Seq Objects\n",
    "proteins = [(protein[0], list(SeqIO.parse(io.StringIO(protein[1]), \"fasta\"))) for protein in proteins]\n",
    "# flatten list\n",
    "proteins = [(protein[0], seq) for protein in proteins for seq in protein[1]]\n",
    "file = open('proteins_2.pickle', 'wb')\n",
    "pickle.dump(proteins, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = open('proteins_2.pickle', 'rb')\n",
    "proteins = pickle.load(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniprot_proteins_2_df = [dict(\n",
    "    gene_id=f\"UniProt:{protein[0]}\",\n",
    "    protein_sequence=str(protein[1].seq),\n",
    "    protein_sequence_len=len(str(protein[1].seq)),\n",
    "    protein_id=protein[1].id,\n",
    "    protein_description=protein[1].description\n",
    ") for protein in proteins]\n",
    "uniprot_proteins_2_df = pd.DataFrame(uniprot_proteins_2_df)\n",
    "uniprot_proteins_2_df.to_parquet(\"protein_uniprot.parquet\", engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniprot_proteins_2_df = pd.read_parquet(\"protein_uniprot.parquet\", engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# uniprot_proteins_df = uniprot_proteins_df[uniprot_proteins_df['protein_sequence_len'] < 2000]\n",
    "utils.analyze_protein_sequence_lens([500, 800, 1000, 2000, 5000, 10000], uniprot_proteins_all_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concat both UniProt Sequences together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniprot_proteins_all_df = pd.concat([uniprot_proteins_df, uniprot_proteins_2_df])\n",
    "uniprot_proteins_all_df.to_parquet(\"protein_rna_inter.parquet\", engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uniprot_proteins_all_df = pd.read_parquet(\"protein_rna_inter.parquet\", engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Protein Sequences from ESM-Model (esm2_t33_650M_UR50D)\n",
    "## Properties: 33 layers, 650 million parameters, embedding dim 1280\n",
    "Note: This model takes around 9GB out of 12GB of available video memory (RTX 2080). However, protein sequences up to a length of 500 take up around 2GB of video memory. Therefore, longer sequences (& all other sequences) will be embedded with a smaller model as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = open('protein_sequence_embeddings_esm2_t33_650M_UR50D.pickle', 'rb')\n",
    "protein_embeddings_big = pickle.load(file)\n",
    "file.close()\n",
    "# Protein Embeddings Big DataFrame\n",
    "peb_df = pd.DataFrame([dict(\n",
    "    protein_sequence=embd[0],\n",
    "    protein_embedding_big=embd[1]\n",
    ") for embd in protein_embeddings_big])\n",
    "peb_df.to_parquet('protein_sequence_embeddings_esm2_t33_650M_UR50D.parquet', engine='pyarrow', compression=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peb_df = pd.read_parquet('protein_sequence_embeddings_esm2_t33_650M_UR50D.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pass"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
